{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# SubgraphX on BA-Shapes dataset for 2-layer GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-04-29T04:58:21.516309Z",
     "iopub.status.busy": "2024-04-29T04:58:21.515209Z",
     "iopub.status.idle": "2024-04-29T04:58:34.150178Z",
     "shell.execute_reply": "2024-04-29T04:58:34.149468Z",
     "shell.execute_reply.started": "2024-04-29T04:58:21.516252Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "!pip install dive-into-graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-04-29T05:27:46.479796Z",
     "iopub.status.busy": "2024-04-29T05:27:46.479616Z",
     "iopub.status.idle": "2024-04-29T05:29:45.286026Z",
     "shell.execute_reply": "2024-04-29T05:29:45.285260Z",
     "shell.execute_reply.started": "2024-04-29T05:27:46.479780Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "!pip install torch_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-04-29T05:51:10.669120Z",
     "iopub.status.busy": "2024-04-29T05:51:10.656505Z",
     "iopub.status.idle": "2024-04-29T05:53:18.979226Z",
     "shell.execute_reply": "2024-04-29T05:53:18.978583Z",
     "shell.execute_reply.started": "2024-04-29T05:51:10.668984Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "pip install torch-sparse==0.6.13 -f https://pytorch-geometric.com/whl/torch-1.10.0+cu113.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T06:11:51.317564Z",
     "iopub.status.busy": "2024-04-29T06:11:51.316518Z",
     "iopub.status.idle": "2024-04-29T06:11:51.597495Z",
     "shell.execute_reply": "2024-04-29T06:11:51.594756Z",
     "shell.execute_reply.started": "2024-04-29T06:11:51.317469Z"
    }
   },
   "source": [
    "conda install pyg -c pyg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T01:06:51.679115Z",
     "iopub.status.busy": "2024-04-30T01:06:51.678199Z",
     "iopub.status.idle": "2024-04-30T01:06:51.706482Z",
     "shell.execute_reply": "2024-04-30T01:06:51.705717Z",
     "shell.execute_reply.started": "2024-04-30T01:06:51.679075Z"
    }
   },
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-04-29T16:30:01.430632Z",
     "iopub.status.busy": "2024-04-29T16:30:01.429450Z",
     "iopub.status.idle": "2024-04-29T16:30:04.158879Z",
     "shell.execute_reply": "2024-04-29T16:30:04.158045Z",
     "shell.execute_reply.started": "2024-04-29T16:30:01.430533Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-04-29T16:30:14.111457Z",
     "iopub.status.busy": "2024-04-29T16:30:14.109343Z",
     "iopub.status.idle": "2024-04-29T16:31:38.638037Z",
     "shell.execute_reply": "2024-04-29T16:31:38.637385Z",
     "shell.execute_reply.started": "2024-04-29T16:30:14.111386Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "!pip install torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.2.2+cpu.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-04-30T01:23:36.535828Z",
     "iopub.status.busy": "2024-04-30T01:23:36.535312Z",
     "iopub.status.idle": "2024-04-30T01:26:18.907036Z",
     "shell.execute_reply": "2024-04-30T01:26:18.906029Z",
     "shell.execute_reply.started": "2024-04-30T01:23:36.535795Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "!pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.2.0+cpu.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-04-30T01:10:31.214233Z",
     "iopub.status.busy": "2024-04-30T01:10:31.213777Z",
     "iopub.status.idle": "2024-04-30T01:12:31.448728Z",
     "shell.execute_reply": "2024-04-30T01:12:31.447250Z",
     "shell.execute_reply.started": "2024-04-30T01:10:31.214198Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "!pip install torch-sparse==0.6.18 -f https://data.pyg.org/whl/torch-2.2.2+cpu.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-04-30T01:22:44.079642Z",
     "iopub.status.busy": "2024-04-30T01:22:44.079206Z",
     "iopub.status.idle": "2024-04-30T01:23:02.276447Z",
     "shell.execute_reply": "2024-04-30T01:23:02.275745Z",
     "shell.execute_reply.started": "2024-04-30T01:22:44.079610Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "!conda install torch_sparse -c pyg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-04-29T19:02:55.757914Z",
     "iopub.status.busy": "2024-04-29T19:02:55.755474Z",
     "iopub.status.idle": "2024-04-29T19:04:58.842279Z",
     "shell.execute_reply": "2024-04-29T19:04:58.841285Z",
     "shell.execute_reply.started": "2024-04-29T19:02:55.757838Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "!pip install torch-sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T04:12:44.709025Z",
     "iopub.status.busy": "2024-04-30T04:12:44.707783Z",
     "iopub.status.idle": "2024-04-30T04:12:48.822893Z",
     "shell.execute_reply": "2024-04-30T04:12:48.822260Z",
     "shell.execute_reply.started": "2024-04-30T04:12:44.708976Z"
    }
   },
   "source": [
    "!pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T02:06:38.258660Z",
     "iopub.status.busy": "2024-05-09T02:06:38.256408Z",
     "iopub.status.idle": "2024-05-09T02:06:38.340066Z",
     "shell.execute_reply": "2024-05-09T02:06:38.339106Z",
     "shell.execute_reply.started": "2024-05-09T02:06:38.258150Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "\n",
    "from digg.xgraph.dataset import SynGraphDataset,MoleculeDataset\n",
    "from digg.xgraph.models import *\n",
    "from digg.xgraph.utils.compatibility import compatible_state_dict\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rdkit\n",
      "  Downloading rdkit-2023.9.6-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: numpy in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from rdkit) (1.26.4)\n",
      "Requirement already satisfied: Pillow in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from rdkit) (10.3.0)\n",
      "Downloading rdkit-2023.9.6-cp310-cp310-macosx_11_0_arm64.whl (27.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.6/27.6 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rdkit\n",
      "Successfully installed rdkit-2023.9.6\n"
     ]
    }
   ],
   "source": [
    "!pip install rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T02:06:43.778415Z",
     "iopub.status.busy": "2024-05-09T02:06:43.777503Z",
     "iopub.status.idle": "2024-05-09T02:06:44.016618Z",
     "shell.execute_reply": "2024-05-09T02:06:44.016141Z",
     "shell.execute_reply.started": "2024-05-09T02:06:43.778374Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:301: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# dataset = SynGraphDataset('./datasets', 'BA_shapes')\n",
    "# dataset = MoleculeDataset('./datasets', 'mutag')\n",
    "dataset = MoleculeDataset(root='.', name='MUTAG')\n",
    "dataset.data.x = dataset.data.x.to(torch.float32)\n",
    "dataset.data.x = dataset.data.x[:, :1]\n",
    "dim_node = dataset.num_node_features\n",
    "dim_edge = dataset.num_edge_features\n",
    "num_classes = dataset.num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load model and checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T02:06:46.678805Z",
     "iopub.status.busy": "2024-05-09T02:06:46.677948Z",
     "iopub.status.idle": "2024-05-09T02:06:46.813906Z",
     "shell.execute_reply": "2024-05-09T02:06:46.813383Z",
     "shell.execute_reply.started": "2024-05-09T02:06:46.678762Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN_2l(\n",
       "  (conv1): GCNConv(1, 6)\n",
       "  (convs): ModuleList(\n",
       "    (0): GCNConv(6, 6)\n",
       "  )\n",
       "  (relu1): ReLU()\n",
       "  (relus): ModuleList(\n",
       "    (0): ReLU()\n",
       "  )\n",
       "  (readout): GlobalMeanPool()\n",
       "  (ffn): Sequential(\n",
       "    (0): Linear(in_features=6, out_features=2, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def check_checkpoints(root='./'):\n",
    "#     if osp.exists(osp.join(root, 'checkpoints')):\n",
    "#         return\n",
    "#     url = ('https://github.com/divelab/DIG_storage/raw/main/xgraph/checkpoints.zip')\n",
    "#     path = download_url(url, root)\n",
    "#     extract_zip(path, root)\n",
    "#     os.unlink(path)\n",
    "\n",
    "\n",
    "model = GCN_2l(model_level='graph', dim_node=dim_node, dim_hidden=6, num_classes=num_classes)\n",
    "model.to(device)\n",
    "# check_checkpoints()\n",
    "# ckpt_path = osp.join('checkpoints', 'ba_shapes', 'GCN_2l', '0', 'GCN_2l_best.ckpt')\n",
    "# state_dict = compatible_state_dict(torch.load(ckpt_path, map_location='cpu')['state_dict'])\n",
    "# model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T07:19:19.415626Z",
     "iopub.status.busy": "2024-05-08T07:19:19.415441Z",
     "iopub.status.idle": "2024-05-08T07:19:19.418194Z",
     "shell.execute_reply": "2024-05-08T07:19:19.417489Z",
     "shell.execute_reply.started": "2024-05-08T07:19:19.415598Z"
    }
   },
   "outputs": [],
   "source": [
    "# from digg.xgraph.models.models import GCNConv,GCN_2l,GNNPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T07:19:19.420489Z",
     "iopub.status.busy": "2024-05-08T07:19:19.419949Z",
     "iopub.status.idle": "2024-05-08T07:19:19.423618Z",
     "shell.execute_reply": "2024-05-08T07:19:19.423212Z",
     "shell.execute_reply.started": "2024-05-08T07:19:19.420474Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T19:13:20.693196Z",
     "iopub.status.busy": "2024-04-29T19:13:20.692299Z",
     "iopub.status.idle": "2024-04-29T19:13:20.700710Z",
     "shell.execute_reply": "2024-04-29T19:13:20.699732Z",
     "shell.execute_reply.started": "2024-04-29T19:13:20.693154Z"
    }
   },
   "source": [
    "class GNNPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T19:13:21.383426Z",
     "iopub.status.busy": "2024-04-29T19:13:21.382383Z",
     "iopub.status.idle": "2024-04-29T19:13:21.392204Z",
     "shell.execute_reply": "2024-04-29T19:13:21.391459Z",
     "shell.execute_reply.started": "2024-04-29T19:13:21.383389Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from digg.xgraph.method import SubgraphX\n",
    "\n",
    "explainer = SubgraphX(model, num_classes=4, device=device,\n",
    "                      explain_graph=False, reward_method='nc_mc_l_shapley')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build max degree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T07:19:19.424730Z",
     "iopub.status.busy": "2024-05-08T07:19:19.424429Z",
     "iopub.status.idle": "2024-05-08T07:19:19.429453Z",
     "shell.execute_reply": "2024-05-08T07:19:19.427275Z",
     "shell.execute_reply.started": "2024-05-08T07:19:19.424677Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.typing import SparseTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T07:19:19.431512Z",
     "iopub.status.busy": "2024-05-08T07:19:19.430938Z",
     "iopub.status.idle": "2024-05-08T07:19:20.245750Z",
     "shell.execute_reply": "2024-05-08T07:19:20.243425Z",
     "shell.execute_reply.started": "2024-05-08T07:19:19.431437Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y9/hy0mnzl536ng5c4qz99ppmf00000gn/T/ipykernel_18265/2731902037.py:12: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np \n",
    "import time\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "# import seaborn as sns\n",
    "# sns.reset_orig()\n",
    "# sns.set()\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "# Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "# PyTorch Lightning\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "    !pip install --quiet pytorch-lightning>=1.4\n",
    "    import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = \"../data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"../saved_models/tutorial7\"\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"mps\")\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T04:54:32.757781Z",
     "iopub.status.busy": "2024-04-30T04:54:32.757615Z",
     "iopub.status.idle": "2024-04-30T04:54:35.270053Z",
     "shell.execute_reply": "2024-04-30T04:54:35.269343Z",
     "shell.execute_reply.started": "2024-04-30T04:54:32.757769Z"
    }
   },
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-30T04:54:35.271092Z",
     "iopub.status.busy": "2024-04-30T04:54:35.270913Z",
     "iopub.status.idle": "2024-04-30T04:54:37.570740Z",
     "shell.execute_reply": "2024-04-30T04:54:37.570026Z",
     "shell.execute_reply.started": "2024-04-30T04:54:35.271072Z"
    }
   },
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.246066Z",
     "iopub.status.idle": "2024-05-08T07:19:20.246177Z",
     "shell.execute_reply": "2024-05-08T07:19:20.246121Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.246116Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch_geometric.nn as geom_nn\n",
    "import torch_geometric.data as geom_data\n",
    "gnn_layer_by_name = {\n",
    "    \"GCN\": geom_nn.GCNConv,\n",
    "    \"GAT\": geom_nn.GATConv,\n",
    "    \"GIN\": geom_nn.GINConv,\n",
    "    \"GraphConv\": geom_nn.GraphConv\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.246620Z",
     "iopub.status.idle": "2024-05-08T07:19:20.246724Z",
     "shell.execute_reply": "2024-05-08T07:19:20.246668Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.246664Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_networkx, from_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.247182Z",
     "iopub.status.idle": "2024-05-08T07:19:20.247315Z",
     "shell.execute_reply": "2024-05-08T07:19:20.247250Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.247245Z"
    }
   },
   "outputs": [],
   "source": [
    "class GNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in, c_hidden, c_out, num_layers=2, layer_name=\"GraphConv\", dp_rate=0.1, **kwargs):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Dimension of input features\n",
    "            c_hidden - Dimension of hidden features\n",
    "            c_out - Dimension of the output features. Usually number of classes in classification\n",
    "            num_layers - Number of \"hidden\" graph layers\n",
    "            layer_name - String of the graph layer to use\n",
    "            dp_rate - Dropout rate to apply throughout the network\n",
    "            kwargs - Additional arguments for the graph layer (e.g. number of heads for GAT)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        gnn_layer = gnn_layer_by_name[layer_name]\n",
    "        \n",
    "        layers = []\n",
    "        in_channels, out_channels = c_in, c_hidden\n",
    "        for l_idx in range(num_layers-1):\n",
    "            layers += [\n",
    "                gnn_layer(in_channels=in_channels, \n",
    "                          out_channels=out_channels,\n",
    "                          **kwargs),\n",
    "                nn.ReLU(inplace=True)\n",
    "                # ,nn.Dropout(dp_rate)\n",
    "            ]\n",
    "            in_channels = c_hidden\n",
    "        layers += [gnn_layer(in_channels=in_channels, \n",
    "                             out_channels=c_out,\n",
    "                             **kwargs)]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            x - Input features per node\n",
    "            edge_index - List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "        \"\"\"\n",
    "        for l in self.layers:\n",
    "            # For graph layers, we need to add the \"edge_index\" tensor as additional input\n",
    "            # All PyTorch Geometric graph layer inherit the class \"MessagePassing\", hence\n",
    "            # we can simply check the class type.\n",
    "            if isinstance(l, geom_nn.MessagePassing):\n",
    "                x = l(x, edge_index)\n",
    "            else:\n",
    "                x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.247987Z",
     "iopub.status.idle": "2024-05-08T07:19:20.248133Z",
     "shell.execute_reply": "2024-05-08T07:19:20.248058Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.248053Z"
    }
   },
   "outputs": [],
   "source": [
    "# Small function for printing the test scores\n",
    "def print_results(result_dict):\n",
    "    if \"train\" in result_dict:\n",
    "        print(f\"Train accuracy: {(100.0*result_dict['train']):4.2f}%\")\n",
    "    if \"val\" in result_dict:\n",
    "        print(f\"Val accuracy:   {(100.0*result_dict['val']):4.2f}%\")\n",
    "    print(f\"Test accuracy:  {(100.0*result_dict['test']):4.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.248974Z",
     "iopub.status.idle": "2024-05-08T07:19:20.249549Z",
     "shell.execute_reply": "2024-05-08T07:19:20.249397Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.249388Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.251216Z",
     "iopub.status.idle": "2024-05-08T07:19:20.251500Z",
     "shell.execute_reply": "2024-05-08T07:19:20.251361Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.251355Z"
    }
   },
   "outputs": [],
   "source": [
    "tu_dataset = torch_geometric.datasets.TUDataset(root=DATASET_PATH, name=\"ENZYMES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.252849Z",
     "iopub.status.idle": "2024-05-08T07:19:20.253845Z",
     "shell.execute_reply": "2024-05-08T07:19:20.253486Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.253432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data object: Data(x=[19580, 3], edge_index=[2, 74564], y=[600])\n",
      "Length: 600\n",
      "Average label: 2.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data object:\", tu_dataset.data)\n",
    "print(\"Length:\", len(tu_dataset))\n",
    "print(f\"Average label: {tu_dataset.data.y.float().mean().item():4.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.255284Z",
     "iopub.status.idle": "2024-05-08T07:19:20.255910Z",
     "shell.execute_reply": "2024-05-08T07:19:20.255789Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.255783Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "tu2=tu_dataset.copy()\n",
    "type(tu2.data)\n",
    "for i in range(len(tu2.y)): \n",
    "    tu2.y[i]=max(torch.bincount(tu2[i].edge_index[0,:]))\n",
    "    # tu2.y[i]=sum(torch.bincount(tu2[i].edge_index[0,:]))\n",
    "    thres=6\n",
    "tu2.data.y=(tu2.y>thres).long()\n",
    "# torch.manual_seed(42)\n",
    "# tu_dataset.shuffle()\n",
    "# train_dataset = tu_dataset[:500]\n",
    "# test_dataset = tu_dataset[500:]\n",
    "torch.manual_seed(42)\n",
    "tu2_shuffle=tu2.shuffle()\n",
    "train_dataset = tu2_shuffle[:500]\n",
    "test_dataset = tu2_shuffle[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.260474Z",
     "iopub.status.idle": "2024-05-08T07:19:20.260664Z",
     "shell.execute_reply": "2024-05-08T07:19:20.260602Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.260596Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "graph_train_loader = geom_data.DataLoader(train_dataset, batch_size=15, shuffle=True)\n",
    "graph_val_loader = geom_data.DataLoader(test_dataset, batch_size=15) # Additional loader if you want to change to a larger dataset\n",
    "graph_test_loader = geom_data.DataLoader(test_dataset, batch_size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.261125Z",
     "iopub.status.idle": "2024-05-08T07:19:20.261230Z",
     "shell.execute_reply": "2024-05-08T07:19:20.261175Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.261171Z"
    }
   },
   "source": [
    "batch = next(iter(graph_test_loader))\n",
    "print(\"Batch:\", batch)\n",
    "print(\"Labels:\", batch.y[:10])\n",
    "print(\"Batch indices:\", batch.batch[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.261951Z",
     "iopub.status.idle": "2024-05-08T07:19:20.262124Z",
     "shell.execute_reply": "2024-05-08T07:19:20.262016Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.262012Z"
    }
   },
   "outputs": [],
   "source": [
    "class GraphGNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in, c_hidden, c_out, dp_rate_linear=0.5, **kwargs):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Dimension of input features\n",
    "            c_hidden - Dimension of hidden features\n",
    "            c_out - Dimension of output features (usually number of classes)\n",
    "            dp_rate_linear - Dropout rate before the linear layer (usually much higher than inside the GNN)\n",
    "            kwargs - Additional arguments for the GNNModel object\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.GNN = GNNModel(c_in=c_in, \n",
    "                            c_hidden=c_hidden, \n",
    "                            c_out=c_hidden, # Not our prediction output yet!\n",
    "                            **kwargs)\n",
    "        self.head = nn.Sequential(\n",
    "            # nn.Dropout(dp_rate_linear),\n",
    "            nn.Linear(c_hidden, c_out)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, batch_idx):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            x - Input features per node\n",
    "            edge_index - List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "            batch_idx - Index of batch element for each node\n",
    "        \"\"\"\n",
    "        x = self.GNN(x, edge_index)\n",
    "        # x = geom_nn.global_mean_pool(x, batch_idx) # Average pooling\n",
    "        x = geom_nn.global_max_pool(x, batch_idx) # Average pooling\n",
    "        # x = geom_nn.global_add_pool(x, batch_idx) # sum pooling\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.262590Z",
     "iopub.status.idle": "2024-05-08T07:19:20.262759Z",
     "shell.execute_reply": "2024-05-08T07:19:20.262653Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.262649Z"
    }
   },
   "outputs": [],
   "source": [
    "class GraphLevelGNN(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, **model_kwargs):\n",
    "        super().__init__()\n",
    "        # Saving hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.model = GraphGNNModel(**model_kwargs)\n",
    "        self.loss_module = nn.BCEWithLogitsLoss() if self.hparams.c_out == 1 else nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, data, mode=\"train\"):\n",
    "        x, edge_index, batch_idx = data.x, data.edge_index, data.batch\n",
    "        x = self.model(x, edge_index, batch_idx)\n",
    "        x = x.squeeze(dim=-1)\n",
    "        \n",
    "        if self.hparams.c_out == 1:\n",
    "            preds = (x > 0).float()\n",
    "            try: \n",
    "                data.y = data.y.float()\n",
    "            except: pass\n",
    "        else:\n",
    "            preds = x.argmax(dim=-1)\n",
    "        try: \n",
    "            loss = self.loss_module(x, data.y)\n",
    "            acc = (preds == data.y).sum().float() / preds.shape[0]\n",
    "        except:\n",
    "            loss = 0\n",
    "            acc = 0\n",
    "\n",
    "        return loss,acc,preds\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=1e-2, weight_decay=0.0) # High lr because of small dataset and small model\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc,_ = self.forward(batch, mode=\"train\")\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', acc)\n",
    "        return loss\n",
    "\n",
    "    # def validation_step(self, batch, batch_idx):\n",
    "    #     _, acc,preds = self.forward(batch, mode=\"val\")\n",
    "    #     self.log('val_acc', acc)\n",
    "    #     # self.log('val_pred', preds)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        _, acc,_ = self.forward(batch, mode=\"test\")\n",
    "        self.log('test_acc', acc)\n",
    "        # self.log('test_pred', pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.263472Z",
     "iopub.status.idle": "2024-05-08T07:19:20.263677Z",
     "shell.execute_reply": "2024-05-08T07:19:20.263600Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.263592Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_graph_classifier(model_name,train_loader=graph_train_loader,test_loader=graph_test_loader, **model_kwargs):\n",
    "    pl.seed_everything(42)\n",
    "    \n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "    root_dir = os.path.join(CHECKPOINT_PATH, \"GraphLevel\" + model_name)\n",
    "    os.makedirs(root_dir, exist_ok=True)\n",
    "    trainer = pl.Trainer(default_root_dir=root_dir,\n",
    "                         # callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n",
    "                         accelerator=\"cpu\",# if str(device).startswith(\"cuda\") else \"cpu\",\n",
    "                         devices=1,\n",
    "                         max_epochs=500,\n",
    "                         enable_progress_bar=False)\n",
    "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"GraphLevel{model_name}.ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        # print(\"Found pretrained model, loading...\")\n",
    "        # model = GraphLevelGNN.load_from_checkpoint(pretrained_filename)\n",
    "        pl.seed_everything(42)\n",
    "        model = GraphLevelGNN(c_in=tu2.num_node_features, \n",
    "                              c_out=1 if tu2.num_classes==2 else tu2.num_classes, \n",
    "                              **model_kwargs)\n",
    "        trainer.fit(model, graph_train_loader, graph_val_loader)\n",
    "        # model = GraphLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "    else:\n",
    "        pl.seed_everything(42)\n",
    "        model = GraphLevelGNN(c_in=tu2.num_node_features, \n",
    "                              c_out=1 if tu2.num_classes==2 else tu2.num_classes, \n",
    "                              **model_kwargs)\n",
    "        trainer.fit(model, graph_train_loader, graph_val_loader)\n",
    "        # model = GraphLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "    # Test best model on validation and test set\n",
    "    train_result = trainer.test(model, train_loader, verbose=False)\n",
    "    test_result = trainer.test(model, test_loader, verbose=False)\n",
    "    # test_pred = trainer.predict(model, graph_test_loader, return_predictions=True)\n",
    "    result = {\"test\": test_result[0]['test_acc'], \"train\": train_result[0]['test_acc']\n",
    "              # ,\"pred_y\": test_pred\n",
    "            } \n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.264714Z",
     "iopub.status.idle": "2024-05-08T07:19:20.264903Z",
     "shell.execute_reply": "2024-05-08T07:19:20.264790Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.264785Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "Seed set to 42\n",
      "/Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:72: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "\n",
      "  | Name        | Type              | Params\n",
      "--------------------------------------------------\n",
      "0 | model       | GraphGNNModel     | 1.2 K \n",
      "1 | loss_module | BCEWithLogitsLoss | 0     \n",
      "--------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "/Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (34) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "/Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "/Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:492: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    }
   ],
   "source": [
    "model, result = train_graph_classifier(model_name=\"GraphConv\", \n",
    "                                       c_hidden=16, \n",
    "                                       layer_name=\"GraphConv\", \n",
    "                                       num_layers=3, \n",
    "                                       dp_rate_linear=0,\n",
    "                                       dp_rate=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.267274Z",
     "iopub.status.idle": "2024-05-08T07:19:20.268094Z",
     "shell.execute_reply": "2024-05-08T07:19:20.267693Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.267661Z"
    }
   },
   "outputs": [],
   "source": [
    "tu2[0].x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.271400Z",
     "iopub.status.idle": "2024-05-08T07:19:20.272288Z",
     "shell.execute_reply": "2024-05-08T07:19:20.271905Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.271897Z"
    }
   },
   "outputs": [],
   "source": [
    "model(tu2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.274172Z",
     "iopub.status.idle": "2024-05-08T07:19:20.275974Z",
     "shell.execute_reply": "2024-05-08T07:19:20.275291Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.275276Z"
    }
   },
   "outputs": [],
   "source": [
    "tu2[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.279032Z",
     "iopub.status.idle": "2024-05-08T07:19:20.279983Z",
     "shell.execute_reply": "2024-05-08T07:19:20.279721Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.279712Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from digg.xgraph.method import SubgraphX\n",
    "\n",
    "explainer = SubgraphX(model, num_classes=2, device=device,\n",
    "                      explain_graph=True, reward_method='mc_shapley')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.281510Z",
     "iopub.status.idle": "2024-05-08T07:19:20.282079Z",
     "shell.execute_reply": "2024-05-08T07:19:20.281820Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.281813Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tu2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# node_indices = torch.where(dataset[0].test_mask * dataset[0].y != 0)[0].tolist()\u001b[39;00m\n\u001b[1;32m      8\u001b[0m data \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 9\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mtu2\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# from digg.xgraph.method.subgraphx import PlotUtils\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdigg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxgraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmethod\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msubgraphx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_closest_node_result\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tu2' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Create data collector and explanation processor ---\n",
    "from digg.xgraph.evaluation import XCollector\n",
    "\n",
    "x_collector = XCollector()\n",
    "\n",
    "index = -1\n",
    "# node_indices = torch.where(dataset[0].test_mask * dataset[0].y != 0)[0].tolist()\n",
    "data = dataset[0]\n",
    "data = tu2[0]\n",
    "\n",
    "# from digg.xgraph.method.subgraphx import PlotUtils\n",
    "from digg.xgraph.method.subgraphx import find_closest_node_result\n",
    "\n",
    "# Visualization\n",
    "max_nodes = 5\n",
    "# node_idx = node_indices[20]\n",
    "print(f'explain graph node {node_idx}')\n",
    "data.to(device)\n",
    "# logits = model(data.x, data.edge_index)\n",
    "# prediction = logits[node_idx].argmax(-1).item()\n",
    "\n",
    "prediction = model(data.x, data.edge_index)[-1]\n",
    "\n",
    "\n",
    "_, explanation_results, related_preds = explainer(data.x, data.edge_index, node_idx=node_idx, max_nodes=max_nodes)\n",
    "\n",
    "explanation_results = explanation_results[prediction]\n",
    "explanation_results = explainer.read_from_MCTSInfo_list(explanation_results)\n",
    "\n",
    "# plotutils = PlotUtils(dataset_name='ba_shapes', is_show=True)\n",
    "# explainer.visualization(explanation_results,\n",
    "#                         max_nodes=max_nodes,\n",
    "#                         plot_utils=plotutils,\n",
    "#                         y=data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.283139Z",
     "iopub.status.idle": "2024-05-08T07:19:20.283436Z",
     "shell.execute_reply": "2024-05-08T07:19:20.283332Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.283320Z"
    }
   },
   "outputs": [],
   "source": [
    "Downloads/DIG/digg/xgraph/models/models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re-prod GCN_2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T02:07:03.553720Z",
     "iopub.status.busy": "2024-05-09T02:07:03.551684Z",
     "iopub.status.idle": "2024-05-09T02:07:03.570833Z",
     "shell.execute_reply": "2024-05-09T02:07:03.570084Z",
     "shell.execute_reply.started": "2024-05-09T02:07:03.553655Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as gnn\n",
    "from torch_geometric.utils.loop import add_self_loops, remove_self_loops\n",
    "from torch_geometric.data.batch import Batch\n",
    "\n",
    "from typing import Callable, Union, Tuple\n",
    "from torch_geometric.typing import OptPairTensor, Adj, OptTensor, Size\n",
    "from torch import Tensor\n",
    "# from torch_geometric.inspector import Inspector as inspector #bw \n",
    "\n",
    "# from torch_sparse import SparseTensor\n",
    "\n",
    "\n",
    "class GNNBasic(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def arguments_read(self, *args, **kwargs):\n",
    "\n",
    "        data: Batch = kwargs.get('data') or None\n",
    "\n",
    "        if not data:\n",
    "            if not args:\n",
    "                assert 'x' in kwargs\n",
    "                assert 'edge_index' in kwargs\n",
    "                x, edge_index = kwargs['x'], kwargs['edge_index'],\n",
    "                batch = kwargs.get('batch')\n",
    "                if batch is None:\n",
    "                    batch = torch.zeros(kwargs['x'].shape[0], dtype=torch.int64, device=x.device)\n",
    "            elif len(args) == 2:\n",
    "                x, edge_index = args[0], args[1]\n",
    "                batch = torch.zeros(args[0].shape[0], dtype=torch.int64, device=x.device)\n",
    "            elif len(args) == 3:\n",
    "                x, edge_index, batch = args[0], args[1], args[2]\n",
    "            else:\n",
    "                raise ValueError(f\"forward's args should take 2 or 3 arguments but got {len(args)}\")\n",
    "        else:\n",
    "            x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        return x, edge_index, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T02:07:05.897672Z",
     "iopub.status.busy": "2024-05-09T02:07:05.894799Z",
     "iopub.status.idle": "2024-05-09T02:07:05.918872Z",
     "shell.execute_reply": "2024-05-09T02:07:05.918310Z",
     "shell.execute_reply.started": "2024-05-09T02:07:05.897608Z"
    }
   },
   "outputs": [],
   "source": [
    "class GCN_2l(GNNBasic):\n",
    "\n",
    "    def __init__(self, model_level, dim_node, dim_hidden, num_classes):\n",
    "        super().__init__()\n",
    "        num_layer = 2\n",
    "\n",
    "        self.conv1 = GCNConv(dim_node, dim_hidden)\n",
    "        self.convs = nn.ModuleList(\n",
    "            [\n",
    "                GCNConv(dim_hidden, dim_hidden)\n",
    "                for _ in range(num_layer - 1)\n",
    "            ]\n",
    "        )\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relus = nn.ModuleList(\n",
    "            [\n",
    "                nn.ReLU()\n",
    "                for _ in range(num_layer - 1)\n",
    "            ]\n",
    "        )\n",
    "        if model_level == 'node':\n",
    "            self.readout = IdenticalPool()\n",
    "        else:\n",
    "            self.readout = GlobalMeanPool()\n",
    "\n",
    "        self.ffn = nn.Sequential(*(\n",
    "                [nn.Linear(dim_hidden, num_classes)]\n",
    "        ))\n",
    "\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, *args, **kwargs) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        :param Required[data]: Batch - input data\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x, edge_index, batch = self.arguments_read(*args, **kwargs)\n",
    "\n",
    "        post_conv = self.relu1(self.conv1(x, edge_index))\n",
    "        for conv, relu in zip(self.convs, self.relus):\n",
    "            post_conv = relu(conv(post_conv, edge_index))\n",
    "\n",
    "        out_readout = self.readout(post_conv, batch)\n",
    "\n",
    "        out = self.ffn(out_readout)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def get_emb(self, *args, **kwargs) -> torch.Tensor:\n",
    "        x, edge_index, batch = self.arguments_read(*args, **kwargs)\n",
    "        \n",
    "        post_conv = self.relu1(self.conv1(x, edge_index))\n",
    "        for conv, relu in zip(self.convs, self.relus):\n",
    "            post_conv = relu(conv(post_conv, edge_index))\n",
    "            \n",
    "        return post_conv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T02:07:08.162474Z",
     "iopub.status.busy": "2024-05-09T02:07:08.161841Z",
     "iopub.status.idle": "2024-05-09T02:07:08.171764Z",
     "shell.execute_reply": "2024-05-09T02:07:08.170538Z",
     "shell.execute_reply.started": "2024-05-09T02:07:08.162447Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "\n",
    "\n",
    "from digg.xgraph.dataset import SynGraphDataset\n",
    "from digg.xgraph.models import *\n",
    "from digg.xgraph.utils.compatibility import compatible_state_dict\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T02:07:08.818244Z",
     "iopub.status.busy": "2024-05-09T02:07:08.817439Z",
     "iopub.status.idle": "2024-05-09T02:07:08.840740Z",
     "shell.execute_reply": "2024-05-09T02:07:08.840132Z",
     "shell.execute_reply.started": "2024-05-09T02:07:08.818210Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:301: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "dataset = SynGraphDataset('./datasets', 'BA_shapes')\n",
    "dataset.data.x = dataset.data.x.to(torch.float32)\n",
    "dataset.data.x = dataset.data.x[:, :1]\n",
    "dim_node = dataset.num_node_features\n",
    "dim_edge = dataset.num_edge_features\n",
    "num_classes = dataset.num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can correctly run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = SynGraphDataset('./datasets', 'BA_shapes')\n",
    "dataset = MoleculeDataset('./datasets', 'MUTAG')\n",
    "dataset.data.x = dataset.data.x.to(torch.float32)\n",
    "# dataset.data.x = dataset.data.x[:, :1]\n",
    "dim_node = dataset.num_node_features\n",
    "dim_edge = dataset.num_edge_features\n",
    "num_classes = dataset.num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/divelab/DIG/blob/21476b079c9226f38915dcd082b5c2ee0cddaac8/benchmarks/xgraph/gnnNets.py \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "from typing import Union, List\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.nn.conv import GCNConv\n",
    "from torch_geometric.nn.glob import global_mean_pool, global_add_pool, global_max_pool\n",
    "from torch import Tensor\n",
    "# from torch_sparse import SparseTensor, fill_diag\n",
    "from torch_geometric.typing import Adj, OptTensor, Size\n",
    "from torch_geometric.utils import add_self_loops\n",
    "# from dig.xgraph.models import GNNPool\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class GNNBase(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GNNBase, self).__init__()\n",
    "\n",
    "    def _argsparse(self, *args, **kwargs):\n",
    "        r\"\"\" Parse the possible input types.\n",
    "        If the x and edge_index are in args, follow the args.\n",
    "        In other case, find them in kwargs.\n",
    "        \"\"\"\n",
    "        if args:\n",
    "            if len(args) == 1:\n",
    "                data = args[0]\n",
    "                x = data.x\n",
    "                edge_index = data.edge_index\n",
    "                if hasattr(data, 'batch'):\n",
    "                    batch = data.batch\n",
    "                else:\n",
    "                    batch = torch.zeros(x.shape[0], dtype=torch.int64, device=x.device)\n",
    "\n",
    "            elif len(args) == 2:\n",
    "                x, edge_index = args[0], args[1]\n",
    "                batch = torch.zeros(x.shape[0], dtype=torch.int64, device=x.device)\n",
    "\n",
    "            elif len(args) == 3:\n",
    "                x, edge_index, batch = args[0], args[1], args[2]\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"forward's args should take 1, 2 or 3 arguments but got {len(args)}\")\n",
    "        else:\n",
    "            data: Batch = kwargs.get('data')\n",
    "            if not data:\n",
    "                x = kwargs.get('x')\n",
    "                edge_index = kwargs.get('edge_index')\n",
    "                assert x is not None, \"forward's args is empty and required node features x is not in kwargs\"\n",
    "                assert edge_index is not None, \"forward's args is empty and required edge_index is not in kwargs\"\n",
    "                batch = kwargs.get('batch')\n",
    "                if not batch:\n",
    "                    batch = torch.zeros(x.shape[0], dtype=torch.int64, device=x.device)\n",
    "            else:\n",
    "                x = data.x\n",
    "                edge_index = data.edge_index\n",
    "                if hasattr(data, 'batch'):\n",
    "                    batch = data.batch\n",
    "                else:\n",
    "                    batch = torch.zeros(x.shape[0], dtype=torch.int64, device=x.device)\n",
    "        return x, edge_index, batch\n",
    "\n",
    "    def load_state_dict(self, state_dict: 'OrderedDict[str, Tensor]',\n",
    "                        strict: bool = True):\n",
    "        new_state_dict = OrderedDict()\n",
    "        for key in state_dict.keys():\n",
    "            if key in self.state_dict().keys():\n",
    "                new_state_dict[key] = state_dict[key]\n",
    "\n",
    "        super(GNNBase, self).load_state_dict(new_state_dict)\n",
    "\n",
    "\n",
    "class GCNConv(GCNConv):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(GCNConv, self).__init__(*args, **kwargs)\n",
    "        self.edge_weight = None\n",
    "        self.weight = nn.Parameter(self.lin.weight.data.T.clone().detach())\n",
    "\n",
    "    # add edge_weight for normalize=False\n",
    "    def forward(self, x: Tensor, edge_index: Adj,\n",
    "                edge_weight: OptTensor = None) -> Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "\n",
    "        if self.normalize and edge_weight is None:\n",
    "            if isinstance(edge_index, Tensor):\n",
    "                cache = self._cached_edge_index\n",
    "                if cache is None:\n",
    "                    edge_index, edge_weight = gcn_norm(   # yapf: disable\n",
    "                        edge_index, edge_weight, x.size(self.node_dim),\n",
    "                        self.improved, self.add_self_loops, dtype=x.dtype)\n",
    "                    if self.cached:\n",
    "                        self._cached_edge_index = (edge_index, edge_weight)\n",
    "                else:\n",
    "                    edge_index, edge_weight = cache[0], cache[1]\n",
    "\n",
    "            elif isinstance(edge_index, SparseTensor):\n",
    "                cache = self._cached_adj_t\n",
    "                if cache is None:\n",
    "                    edge_index = gcn_norm(\n",
    "                        edge_index, edge_weight, x.size(self.node_dim),\n",
    "                        self.improved, self.add_self_loops, dtype=x.dtype)\n",
    "                    if self.cached:\n",
    "                        self._cached_adj_t = edge_index\n",
    "                else:\n",
    "                    edge_index = cache\n",
    "\n",
    "        # new\n",
    "        elif not self.normalize:\n",
    "            if isinstance(edge_index, Tensor):\n",
    "                cache = self._cached_edge_index\n",
    "                if cache is None:\n",
    "                    if edge_weight is None:\n",
    "                        edge_weight = torch.ones((edge_index.size(1),), device=edge_index.device)\n",
    "                    if self.add_self_loops:\n",
    "                        edge_index, edge_weight = add_self_loops(\n",
    "                            edge_index, edge_weight, num_nodes=x.size(self.node_dim))\n",
    "                    if self.cached:\n",
    "                        self._cached_edge_index = (edge_index, edge_weight)\n",
    "                else:\n",
    "                    edge_index, edge_weight = cache[0], cache[1]\n",
    "\n",
    "            elif isinstance(edge_index, SparseTensor):\n",
    "                cache = self._cached_adj_t\n",
    "                if cache is None:\n",
    "                    adj_t = edge_index\n",
    "                    if not adj_t.has_value():\n",
    "                        adj_t = adj_t.fill_value(1.)\n",
    "                    if self.add_self_loops:\n",
    "                        adj_t = fill_diag(adj_t, 1.)\n",
    "                    edge_index = adj_t\n",
    "                    if self.cached:\n",
    "                        self._cached_adj_t = edge_index\n",
    "\n",
    "        # --- add require_grad ---\n",
    "        edge_weight.requires_grad_(True)\n",
    "\n",
    "        # propagate_type: (x: Tensor, edge_weight: OptTensor)\n",
    "        out = self.propagate(edge_index, x=x, edge_weight=edge_weight,\n",
    "                             size=None)\n",
    "\n",
    "        out = torch.matmul(out, self.weight)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out += self.bias\n",
    "\n",
    "        # --- My: record edge_weight ---\n",
    "        self.edge_weight = edge_weight\n",
    "\n",
    "        return out\n",
    "\n",
    "    def propagate(self, edge_index: Adj, size: Size = None, **kwargs):\n",
    "        size = self.__check_input__(edge_index, size)\n",
    "\n",
    "        # Run \"fused\" message and aggregation (if applicable).\n",
    "        if (isinstance(edge_index, SparseTensor) and self.fuse\n",
    "                and not self._explain):\n",
    "            coll_dict = self.__collect__(self.__fused_user_args__, edge_index,\n",
    "                                         size, kwargs)\n",
    "\n",
    "            msg_aggr_kwargs = self.inspector.distribute(\n",
    "                'message_and_aggregate', coll_dict)\n",
    "            out = self.message_and_aggregate(edge_index, **msg_aggr_kwargs)\n",
    "\n",
    "            update_kwargs = self.inspector.distribute('update', coll_dict)\n",
    "            return self.update(out, **update_kwargs)\n",
    "\n",
    "        # Otherwise, run both functions in separation.\n",
    "        elif isinstance(edge_index, Tensor) or not self.fuse:\n",
    "            coll_dict = self.__collect__(self.__user_args__, edge_index, size,\n",
    "                                         kwargs)\n",
    "\n",
    "            msg_kwargs = self.inspector.distribute('message', coll_dict)\n",
    "            out = self.message(**msg_kwargs)\n",
    "\n",
    "            # For `GNNExplainer`, we require a separate message and aggregate\n",
    "            # procedure since this allows us to inject the `edge_mask` into the\n",
    "            # message passing computation scheme.\n",
    "            if self._explain:\n",
    "                edge_mask = self.__edge_mask__\n",
    "                # Some ops add self-loops to `edge_index`. We need to do the\n",
    "                # same for `edge_mask` (but do not train those).\n",
    "                if out.size(self.node_dim) != edge_mask.size(0):\n",
    "                    loop = edge_mask.new_ones(size[0])\n",
    "                    edge_mask = torch.cat([edge_mask, loop], dim=0)\n",
    "                assert out.size(self.node_dim) == edge_mask.size(0)\n",
    "                out = out * edge_mask.view([-1] + [1] * (out.dim() - 1))\n",
    "\n",
    "            aggr_kwargs = self.inspector.distribute('aggregate', coll_dict)\n",
    "            out = self.aggregate(out, **aggr_kwargs)\n",
    "\n",
    "            update_kwargs = self.inspector.distribute('update', coll_dict)\n",
    "            return self.update(out, **update_kwargs)\n",
    "\n",
    "\n",
    "class GCNNet(GNNBase):\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 output_dim: int,\n",
    "                 gnn_latent_dim: Union[List[int]],\n",
    "                 gnn_dropout: float = 0.0,\n",
    "                 gnn_emb_normalization: bool = False,\n",
    "                 gcn_adj_normalization: bool = True,\n",
    "                 add_self_loop: bool = True,\n",
    "                 gnn_nonlinear: str = 'relu',\n",
    "                 readout: str = 'mean',\n",
    "                 concate: bool = False,\n",
    "                 fc_latent_dim: Union[List[int]] = [],\n",
    "                 fc_dropout: float = 0.0,\n",
    "                 fc_nonlinear: str = 'relu',\n",
    "                 ):\n",
    "        super(GCNNet, self).__init__()\n",
    "        # first and last layer - dim_features and classes\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        # GNN part\n",
    "        self.gnn_latent_dim = gnn_latent_dim\n",
    "        self.gnn_dropout = gnn_dropout\n",
    "        self.num_gnn_layers = len(self.gnn_latent_dim)\n",
    "        self.add_self_loop = add_self_loop\n",
    "        self.gnn_emb_normalization = gnn_emb_normalization\n",
    "        self.gcn_adj_normalization = gcn_adj_normalization\n",
    "        self.gnn_nonlinear = get_nonlinear(gnn_nonlinear)\n",
    "        self.concate = concate\n",
    "        # readout\n",
    "        self.readout_layer = GNNPool(readout)\n",
    "        # FC part\n",
    "        self.fc_latent_dim = fc_latent_dim\n",
    "        self.fc_dropout = fc_dropout\n",
    "        self.num_mlp_layers = len(self.fc_latent_dim) + 1\n",
    "        self.fc_nonlinear = get_nonlinear(fc_nonlinear)\n",
    "\n",
    "        if self.concate:\n",
    "            self.emb_dim = sum(self.gnn_latent_dim)\n",
    "        else:\n",
    "            self.emb_dim = self.gnn_latent_dim[-1]\n",
    "\n",
    "        # GNN layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(GCNConv(input_dim, self.gnn_latent_dim[0],\n",
    "                                  add_self_loops=self.add_self_loop,\n",
    "                                  normalize=self.gcn_adj_normalization))\n",
    "        for i in range(1, self.num_gnn_layers):\n",
    "            self.convs.append(GCNConv(self.gnn_latent_dim[i - 1], self.gnn_latent_dim[i],\n",
    "                                      add_self_loops=self.add_self_loop,\n",
    "                                      normalize=self.gcn_adj_normalization))\n",
    "        # FC layers\n",
    "        self.mlps = nn.ModuleList()\n",
    "        if self.num_mlp_layers > 1:\n",
    "            self.mlps.append(nn.Linear(self.emb_dim, self.fc_latent_dim[0]))\n",
    "\n",
    "            for i in range(1, self.num_mlp_layers-1):\n",
    "                self.mlps.append(nn.Linear(self.fc_latent_dim[i-1], self.fc_latent_dim[1]))\n",
    "            self.mlps.append(nn.Linear(self.fc_latent_dim[-1], self.output_dim))\n",
    "        else:\n",
    "            self.mlps.append(nn.Linear(self.emb_dim, self.output_dim))\n",
    "\n",
    "    def device(self):\n",
    "        return self.convs[0].weight.device\n",
    "\n",
    "    def get_emb(self, *args, **kwargs):\n",
    "        #  node embedding for GNN\n",
    "        x, edge_index, _ = self._argsparse(*args, **kwargs)\n",
    "        xs = []\n",
    "        for i in range(self.num_gnn_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            if self.gnn_emb_normalization:\n",
    "                x = F.normalize(x, p=2, dim=-1)\n",
    "            x = self.gnn_nonlinear(x)\n",
    "            x = F.dropout(x, self.gnn_dropout)\n",
    "            xs.append(x)\n",
    "\n",
    "        if self.concate:\n",
    "            return torch.cat(xs, dim=1)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        _, _, batch = self._argsparse(*args, **kwargs)\n",
    "        # node embedding for GNN\n",
    "        emb = self.get_emb(*args, **kwargs)\n",
    "        # pooling process\n",
    "        x = self.readout_layer(emb, batch)\n",
    "\n",
    "        for i in range(self.num_mlp_layers - 1):\n",
    "            x = self.mlps[i](x)\n",
    "            x = self.fc_nonlinear(x)\n",
    "            x = F.dropout(x, p=self.fc_dropout)\n",
    "\n",
    "        logits = self.mlps[-1](x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T02:07:11.168653Z",
     "iopub.status.busy": "2024-05-09T02:07:11.167057Z",
     "iopub.status.idle": "2024-05-09T02:07:11.202741Z",
     "shell.execute_reply": "2024-05-09T02:07:11.202239Z",
     "shell.execute_reply.started": "2024-05-09T02:07:11.168608Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GCNConv:\n\tMissing key(s) in state_dict: \"bias\", \"weight\", \"lin.weight\". \n\tUnexpected key(s) in state_dict: \"model.gnn_layers.0.weight\", \"model.gnn_layers.0.bias\", \"model.gnn_layers.1.weight\", \"model.gnn_layers.1.bias\", \"model.gnn_layers.2.weight\", \"model.gnn_layers.2.bias\", \"model.mlps.0.weight\", \"model.mlps.0.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m osp\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoints\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmutag_ckpt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGCN_latest.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# state_dict = compatible_state_dict(torch.load(ckpt_path, map_location='cpu')['state_dict'])\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# state_dict = compatible_state_dict(torch.load(ckpt_path, map_location='cpu')['net'])\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/torch/nn/modules/module.py:2189\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2184\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2185\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2186\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2190\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GCNConv:\n\tMissing key(s) in state_dict: \"bias\", \"weight\", \"lin.weight\". \n\tUnexpected key(s) in state_dict: \"model.gnn_layers.0.weight\", \"model.gnn_layers.0.bias\", \"model.gnn_layers.1.weight\", \"model.gnn_layers.1.bias\", \"model.gnn_layers.2.weight\", \"model.gnn_layers.2.bias\", \"model.mlps.0.weight\", \"model.mlps.0.bias\". "
     ]
    }
   ],
   "source": [
    "def check_checkpoints(root='./'):\n",
    "    if osp.exists(osp.join(root, 'checkpoints')):\n",
    "        return\n",
    "    url = ('https://github.com/divelab/DIG_storage/raw/main/xgraph/checkpoints.zip')\n",
    "    path = download_url(url, root)\n",
    "    extract_zip(path, root)\n",
    "    os.unlink(path)\n",
    "\n",
    "model = get_\n",
    "# model = GCNNet( input_dim=dim_node,output_dim=num_classes ) #dim_node=dim_node, dim_hidden=300, num_classes=num_classes)\n",
    "model = GCNConv( in_channels=dim_node,out_channels=num_classes )\n",
    "model.to(device)\n",
    "check_checkpoints()\n",
    "ckpt_path = osp.join('checkpoints', 'mutag_ckpt', 'GCN_latest.pth')\n",
    "# state_dict = compatible_state_dict(torch.load(ckpt_path, map_location='cpu')['state_dict'])\n",
    "# state_dict = compatible_state_dict(torch.load(ckpt_path, map_location='cpu')['net'])\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gnnNets(input_dim, output_dim, model_config):\n",
    "    if model_config.gnn_name.lower() == 'gcn':\n",
    "        gcn_model_param_names = GCNNet.__init__.__code__.co_varnames\n",
    "        gcn_model_params = {param_name: getattr(model_config.param, param_name)\n",
    "                            for param_name in gcn_model_param_names\n",
    "                            if param_name in model_config.param.keys()}\n",
    "        return GCNNet(input_dim=input_dim,\n",
    "                      output_dim=output_dim,\n",
    "                      ** gcn_model_params)\n",
    "    else:\n",
    "        raise ValueError(f\"GNN name should be gcn \"\n",
    "                         f\"and {model_config.gnn_name} is not defined.\")\n",
    "\n",
    "\n",
    "def identity(x: torch.Tensor, batch: torch.Tensor):\n",
    "    return x\n",
    "\n",
    "\n",
    "def cat_max_sum(x, batch):\n",
    "    node_dim = x.shape[-1]\n",
    "    num_node = 25\n",
    "    x = x.reshape(-1, num_node, node_dim)\n",
    "    return torch.cat([x.max(dim=1)[0], x.sum(dim=1)], dim=-1)\n",
    "\n",
    "\n",
    "def get_readout_layers(readout):\n",
    "    readout_func_dict = {\n",
    "        \"mean\": global_mean_pool,\n",
    "        \"sum\": global_add_pool,\n",
    "        \"max\": global_max_pool,\n",
    "        'identity': identity,\n",
    "        \"cat_max_sum\": cat_max_sum,\n",
    "    }\n",
    "    readout_func_dict = {k.lower(): v for k, v in readout_func_dict.items()}\n",
    "    return readout_func_dict[readout.lower()]\n",
    "\n",
    "def get_gnnNets(input_dim, output_dim, model_config):\n",
    "    if model_config.gnn_name.lower() == 'gcn':\n",
    "        gcn_model_param_names = GCNNet.__init__.__code__.co_varnames\n",
    "        gcn_model_params = {param_name: getattr(model_config.param, param_name)\n",
    "                            for param_name in gcn_model_param_names\n",
    "                            if param_name in model_config.param.keys()}\n",
    "        return GCNNet(input_dim=input_dim,\n",
    "                      output_dim=output_dim,\n",
    "                      ** gcn_model_params)\n",
    "    else:\n",
    "        raise ValueError(f\"GNN name should be gcn \"\n",
    "                         f\"and {model_config.gnn_name} is not defined.\")\n",
    "\n",
    "\n",
    "def identity(x: torch.Tensor, batch: torch.Tensor):\n",
    "    return x\n",
    "\n",
    "\n",
    "def cat_max_sum(x, batch):\n",
    "    node_dim = x.shape[-1]\n",
    "    num_node = 25\n",
    "    x = x.reshape(-1, num_node, node_dim)\n",
    "    return torch.cat([x.max(dim=1)[0], x.sum(dim=1)], dim=-1)\n",
    "\n",
    "\n",
    "def get_readout_layers(readout):\n",
    "    readout_func_dict = {\n",
    "        \"mean\": global_mean_pool,\n",
    "        \"sum\": global_add_pool,\n",
    "        \"max\": global_max_pool,\n",
    "        'identity': identity,\n",
    "        \"cat_max_sum\": cat_max_sum,\n",
    "    }\n",
    "    readout_func_dict = {k.lower(): v for k, v in readout_func_dict.items()}\n",
    "    return readout_func_dict[readout.lower()]\n",
    "\n",
    "def get_nonlinear(nonlinear):\n",
    "    nonlinear_func_dict = {\n",
    "        \"relu\": F.relu,\n",
    "        \"leakyrelu\": partial(F.leaky_relu, negative_slope=0.2),\n",
    "        \"sigmoid\": F.sigmoid,\n",
    "        \"elu\": F.elu\n",
    "    }\n",
    "    return nonlinear_func_dict[nonlinear]\n",
    "class GNNPool(GNNPool):\n",
    "    def __init__(self, readout):\n",
    "        super().__init__()\n",
    "        self.readout = get_readout_layers(readout)\n",
    "\n",
    "    def forward(self, x, batch):\n",
    "        return self.readout(x, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['net', 'epoch', 'acc'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(ckpt_path, map_location='cpu').keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T02:07:52.304442Z",
     "iopub.status.busy": "2024-05-09T02:07:52.303307Z",
     "iopub.status.idle": "2024-05-09T02:07:52.428214Z",
     "shell.execute_reply": "2024-05-09T02:07:52.427630Z",
     "shell.execute_reply.started": "2024-05-09T02:07:52.304391Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from digg.xgraph.method import SubgraphX\n",
    "\n",
    "explainer = SubgraphX(model, num_classes=4, device=device,\n",
    "                      explain_graph=False, reward_method='nc_mc_l_shapley')\n",
    "                      \n",
    "\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explain graph node 515\n"
     ]
    },
    {
     "data": {
      "application/pdf": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"371.52pt\" height=\"280.512pt\" viewBox=\"0 0 371.52 280.512\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-05-09T15:03:29.499544</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.0, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 280.512 \n",
       "L 371.52 280.512 \n",
       "L 371.52 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"LineCollection_1\">\n",
       "    <path d=\"M 333.330248 171.717949 \n",
       "L 313.733065 215.023633 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #808080; stroke-width: 3\"/>\n",
       "    <path d=\"M 333.330248 171.717949 \n",
       "L 189.98479 184.482165 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #808080; stroke-width: 3\"/>\n",
       "    <path d=\"M 189.98479 184.482165 \n",
       "L 235.18722 215.016711 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #808080; stroke-width: 3\"/>\n",
       "    <path d=\"M 189.98479 184.482165 \n",
       "L 313.733065 215.023633 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #808080; stroke-width: 3\"/>\n",
       "    <path d=\"M 189.98479 184.482165 \n",
       "L 152.959177 244.6864 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #808080; stroke-width: 3\"/>\n",
       "    <path d=\"M 189.98479 184.482165 \n",
       "L 78.712866 222.071203 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #808080; stroke-width: 3\"/>\n",
       "    <path d=\"M 189.98479 184.482165 \n",
       "L 71.681768 181.968511 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #808080; stroke-width: 3\"/>\n",
       "    <path d=\"M 189.98479 184.482165 \n",
       "L 251.139246 250.219636 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #808080; stroke-width: 3\"/>\n",
       "    <path d=\"M 189.98479 184.482165 \n",
       "L 269.406938 157.667668 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #808080; stroke-width: 3\"/>\n",
       "    <path d=\"M 189.98479 184.482165 \n",
       "L 155.987307 117.203003 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #808080; stroke-width: 3\"/>\n",
       "    <path d=\"M 155.987307 117.203003 \n",
       "L 142.117263 57.550402 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #808080; stroke-width: 3\"/>\n",
       "    <path d=\"M 155.987307 117.203003 \n",
       "L 38.189752 90.369265 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #808080; stroke-width: 3\"/>\n",
       "    <path d=\"M 155.987307 117.203003 \n",
       "L 233.232673 66.053438 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #808080; stroke-width: 3\"/>\n",
       "    <path d=\"M 142.117263 57.550402 \n",
       "L 40.11277 30.292364 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #808080; stroke-width: 3\"/>\n",
       "    <path d=\"M 142.117263 57.550402 \n",
       "L 233.232673 66.053438 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #808080; stroke-width: 3\"/>\n",
       "    <path d=\"M 40.11277 30.292364 \n",
       "L 38.189752 90.369265 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #808080; stroke-width: 3\"/>\n",
       "    <path d=\"M 152.959177 244.6864 \n",
       "L 235.18722 215.016711 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #808080; stroke-width: 3\"/>\n",
       "    <path d=\"M 235.18722 215.016711 \n",
       "L 313.733065 215.023633 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #808080; stroke-width: 3\"/>\n",
       "    <path d=\"M 235.18722 215.016711 \n",
       "L 269.406938 157.667668 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #808080; stroke-width: 3\"/>\n",
       "    <path d=\"M 313.733065 215.023633 \n",
       "L 251.139246 250.219636 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #808080; stroke-width: 3\"/>\n",
       "   </g>\n",
       "   <g id=\"LineCollection_2\">\n",
       "    <path d=\"M 155.987307 117.203003 \n",
       "L 142.117263 57.550402 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #000000; stroke-width: 3\"/>\n",
       "    <path d=\"M 155.987307 117.203003 \n",
       "L 38.189752 90.369265 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #000000; stroke-width: 3\"/>\n",
       "    <path d=\"M 155.987307 117.203003 \n",
       "L 233.232673 66.053438 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #000000; stroke-width: 3\"/>\n",
       "    <path d=\"M 142.117263 57.550402 \n",
       "L 40.11277 30.292364 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #000000; stroke-width: 3\"/>\n",
       "    <path d=\"M 142.117263 57.550402 \n",
       "L 233.232673 66.053438 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #000000; stroke-width: 3\"/>\n",
       "    <path d=\"M 40.11277 30.292364 \n",
       "L 38.189752 90.369265 \n",
       "\" clip-path=\"url(#pb4cf8bf50e)\" style=\"fill: none; stroke: #000000; stroke-width: 3\"/>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_1\">\n",
       "    <defs>\n",
       "     <path id=\"C0_0_dbb33a91c5\" d=\"M 0 8.660254 \n",
       "C 2.296726 8.660254 4.499694 7.747755 6.123724 6.123724 \n",
       "C 7.747755 4.499694 8.660254 2.296726 8.660254 -0 \n",
       "C 8.660254 -2.296726 7.747755 -4.499694 6.123724 -6.123724 \n",
       "C 4.499694 -7.747755 2.296726 -8.660254 0 -8.660254 \n",
       "C -2.296726 -8.660254 -4.499694 -7.747755 -6.123724 -6.123724 \n",
       "C -7.747755 -4.499694 -8.660254 -2.296726 -8.660254 0 \n",
       "C -8.660254 2.296726 -7.747755 4.499694 -6.123724 6.123724 \n",
       "C -4.499694 7.747755 -2.296726 8.660254 0 8.660254 \n",
       "z\n",
       "\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#pb4cf8bf50e)\">\n",
       "     <use xlink:href=\"#C0_0_dbb33a91c5\" x=\"333.330248\" y=\"171.717949\" style=\"fill: #ffa500; stroke: #ffa500\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pb4cf8bf50e)\">\n",
       "     <use xlink:href=\"#C0_0_dbb33a91c5\" x=\"189.98479\" y=\"184.482165\" style=\"fill: #ffa500; stroke: #ffa500\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pb4cf8bf50e)\">\n",
       "     <use xlink:href=\"#C0_0_dbb33a91c5\" x=\"155.987307\" y=\"117.203003\" style=\"fill: #fe0000; stroke: #fe0000\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pb4cf8bf50e)\">\n",
       "     <use xlink:href=\"#C0_0_dbb33a91c5\" x=\"142.117263\" y=\"57.550402\" style=\"fill: #fe0000; stroke: #fe0000\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pb4cf8bf50e)\">\n",
       "     <use xlink:href=\"#C0_0_dbb33a91c5\" x=\"40.11277\" y=\"30.292364\" style=\"fill: #008000; stroke: #008000\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pb4cf8bf50e)\">\n",
       "     <use xlink:href=\"#C0_0_dbb33a91c5\" x=\"38.189752\" y=\"90.369265\" style=\"fill: #008000; stroke: #008000\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pb4cf8bf50e)\">\n",
       "     <use xlink:href=\"#C0_0_dbb33a91c5\" x=\"152.959177\" y=\"244.6864\" style=\"fill: #ffa500; stroke: #ffa500\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pb4cf8bf50e)\">\n",
       "     <use xlink:href=\"#C0_0_dbb33a91c5\" x=\"235.18722\" y=\"215.016711\" style=\"fill: #ffa500; stroke: #ffa500\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pb4cf8bf50e)\">\n",
       "     <use xlink:href=\"#C0_0_dbb33a91c5\" x=\"313.733065\" y=\"215.023633\" style=\"fill: #ffa500; stroke: #ffa500\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pb4cf8bf50e)\">\n",
       "     <use xlink:href=\"#C0_0_dbb33a91c5\" x=\"233.232673\" y=\"66.053438\" style=\"fill: #4970c6; stroke: #4970c6\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pb4cf8bf50e)\">\n",
       "     <use xlink:href=\"#C0_0_dbb33a91c5\" x=\"71.681768\" y=\"181.968511\" style=\"fill: #ffa500; stroke: #ffa500\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pb4cf8bf50e)\">\n",
       "     <use xlink:href=\"#C0_0_dbb33a91c5\" x=\"78.712866\" y=\"222.071203\" style=\"fill: #ffa500; stroke: #ffa500\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pb4cf8bf50e)\">\n",
       "     <use xlink:href=\"#C0_0_dbb33a91c5\" x=\"251.139246\" y=\"250.219636\" style=\"fill: #ffa500; stroke: #ffa500\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pb4cf8bf50e)\">\n",
       "     <use xlink:href=\"#C0_0_dbb33a91c5\" x=\"269.406938\" y=\"157.667668\" style=\"fill: #ffa500; stroke: #ffa500\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_2\">\n",
       "    <defs>\n",
       "     <path id=\"m8b71785a70\" d=\"M 0 12.247449 \n",
       "C 3.248061 12.247449 6.363528 10.95698 8.660254 8.660254 \n",
       "C 10.95698 6.363528 12.247449 3.248061 12.247449 0 \n",
       "C 12.247449 -3.248061 10.95698 -6.363528 8.660254 -8.660254 \n",
       "C 6.363528 -10.95698 3.248061 -12.247449 0 -12.247449 \n",
       "C -3.248061 -12.247449 -6.363528 -10.95698 -8.660254 -8.660254 \n",
       "C -10.95698 -6.363528 -12.247449 -3.248061 -12.247449 0 \n",
       "C -12.247449 3.248061 -10.95698 6.363528 -8.660254 8.660254 \n",
       "C -6.363528 10.95698 -3.248061 12.247449 0 12.247449 \n",
       "z\n",
       "\" style=\"stroke: #fe0000\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#pb4cf8bf50e)\">\n",
       "     <use xlink:href=\"#m8b71785a70\" x=\"155.987307\" y=\"117.203003\" style=\"fill: #fe0000; stroke: #fe0000\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pb4cf8bf50e\">\n",
       "   <rect x=\"7.2\" y=\"7.2\" width=\"357.12\" height=\"266.112\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Create data collector and explanation processor ---\n",
    "from dig.xgraph.evaluation import XCollector\n",
    "\n",
    "x_collector = XCollector()\n",
    "\n",
    "index = -1\n",
    "node_indices = torch.where(dataset[0].test_mask * dataset[0].y != 0)[0].tolist()\n",
    "data = dataset[0]\n",
    "\n",
    "from digg.xgraph.method.subgraphx import PlotUtils\n",
    "from digg.xgraph.method.subgraphx import find_closest_node_result\n",
    "\n",
    "# Visualization\n",
    "max_nodes = 5\n",
    "node_idx = node_indices[20]\n",
    "print(f'explain graph node {node_idx}')\n",
    "data.to(device)\n",
    "logits = model(data.x, data.edge_index)\n",
    "prediction = logits[node_idx].argmax(-1).item()\n",
    "\n",
    "_, explanation_results, related_preds = explainer(data.x, data.edge_index, node_idx=node_idx, max_nodes=max_nodes)\n",
    "\n",
    "explanation_results = explanation_results[prediction]\n",
    "explanation_results = explainer.read_from_MCTSInfo_list(explanation_results)\n",
    "\n",
    "plotutils = PlotUtils(dataset_name='ba_shapes', is_show=True)\n",
    "explainer.visualization(explanation_results,\n",
    "                        max_nodes=max_nodes,\n",
    "                        plot_utils=plotutils,\n",
    "                        y=data.y)\n",
    "# explain graph node 515"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MUTAG(188)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class MarginalSubgraphDataset with abstract methods get, len",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index)\n\u001b[1;32m     20\u001b[0m prediction \u001b[38;5;241m=\u001b[39m logits[node_idx]\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 22\u001b[0m _, explanation_results, related_preds \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m explanation_results \u001b[38;5;241m=\u001b[39m explanation_results[prediction]\n\u001b[1;32m     25\u001b[0m explanation_results \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mread_from_MCTSInfo_list(explanation_results)\n",
      "File \u001b[0;32m~/Downloads/DIG/examples/xgraph/digg/xgraph/method/subgraphx.py:863\u001b[0m, in \u001b[0;36mSubgraphX.__call__\u001b[0;34m(self, x, edge_index, **kwargs)\u001b[0m\n\u001b[1;32m    860\u001b[0m         saved_results \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label_idx, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ex_labels):\n\u001b[0;32m--> 863\u001b[0m     results, related_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mmax_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mnode_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43msaved_MCTSInfo_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msaved_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m     related_preds\u001b[38;5;241m.\u001b[39mappend(related_pred)\n\u001b[1;32m    869\u001b[0m     explanation_results\u001b[38;5;241m.\u001b[39mappend(results)\n",
      "File \u001b[0;32m~/Downloads/DIG/examples/xgraph/digg/xgraph/method/subgraphx.py:771\u001b[0m, in \u001b[0;36mSubgraphX.explain\u001b[0;34m(self, x, edge_index, label, max_nodes, node_idx, saved_MCTSInfo_list)\u001b[0m\n\u001b[1;32m    769\u001b[0m     payoff_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_reward_func(value_func)\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmcts_state_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_mcts_class(x, edge_index, score_func\u001b[38;5;241m=\u001b[39mpayoff_func)\n\u001b[0;32m--> 771\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmcts_state_map\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmcts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;66;03m# l sharply score\u001b[39;00m\n\u001b[1;32m    774\u001b[0m value_func \u001b[38;5;241m=\u001b[39m GnnNetsGC2valueFunc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, target_class\u001b[38;5;241m=\u001b[39mlabel)\n",
      "File \u001b[0;32m~/Downloads/DIG/examples/xgraph/digg/xgraph/method/subgraphx.py:588\u001b[0m, in \u001b[0;36mMCTS.mcts\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe nodes in graph is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mnumber_of_nodes()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rollout_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_rollout):\n\u001b[0;32m--> 588\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmcts_rollout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    590\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrollout_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rollout, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_map)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m states that have been explored.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/DIG/examples/xgraph/digg/xgraph/method/subgraphx.py:573\u001b[0m, in \u001b[0;36mMCTS.mcts_rollout\u001b[0;34m(self, tree_node)\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m find_same_child:\n\u001b[1;32m    571\u001b[0m         tree_node\u001b[38;5;241m.\u001b[39mchildren\u001b[38;5;241m.\u001b[39mappend(new_node)\n\u001b[0;32m--> 573\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree_node\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchildren\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child, score \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tree_node\u001b[38;5;241m.\u001b[39mchildren, scores):\n\u001b[1;32m    575\u001b[0m     child\u001b[38;5;241m.\u001b[39mP \u001b[38;5;241m=\u001b[39m score\n",
      "File \u001b[0;32m~/Downloads/DIG/examples/xgraph/digg/xgraph/method/subgraphx.py:164\u001b[0m, in \u001b[0;36mcompute_scores\u001b[0;34m(score_func, children)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m children:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child\u001b[38;5;241m.\u001b[39mP \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 164\u001b[0m         score \u001b[38;5;241m=\u001b[39m \u001b[43mscore_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoalition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m         score \u001b[38;5;241m=\u001b[39m child\u001b[38;5;241m.\u001b[39mP\n",
      "File \u001b[0;32m~/Downloads/DIG/examples/xgraph/digg/xgraph/method/shapley.py:181\u001b[0m, in \u001b[0;36mmc_shapley\u001b[0;34m(coalition, data, value_func, subgraph_building_method, sample_num)\u001b[0m\n\u001b[1;32m    179\u001b[0m exclude_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(set_exclude_masks, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    180\u001b[0m include_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(set_include_masks, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 181\u001b[0m marginal_contributions \u001b[38;5;241m=\u001b[39m \u001b[43mmarginal_contribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubset_build_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m mc_shapley_value \u001b[38;5;241m=\u001b[39m marginal_contributions\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mc_shapley_value\n",
      "File \u001b[0;32m~/Downloads/DIG/examples/xgraph/digg/xgraph/method/shapley.py:74\u001b[0m, in \u001b[0;36mmarginal_contribution\u001b[0;34m(data, exclude_mask, include_mask, value_func, subgraph_build_func)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmarginal_contribution\u001b[39m(data: Data, exclude_mask: np\u001b[38;5;241m.\u001b[39marray, include_mask: np\u001b[38;5;241m.\u001b[39marray,\n\u001b[1;32m     72\u001b[0m                           value_func, subgraph_build_func):\n\u001b[1;32m     73\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Calculate the marginal value for each pair. Here exclude_mask and include_mask are node mask. \"\"\"\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m     marginal_subgraph_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mMarginalSubgraphDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraph_build_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     dataloader \u001b[38;5;241m=\u001b[39m DataLoader(marginal_subgraph_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     77\u001b[0m     marginal_contribution_list \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class MarginalSubgraphDataset with abstract methods get, len"
     ]
    }
   ],
   "source": [
    "# --- Create data collector and explanation processor ---\n",
    "from digg.xgraph.evaluation import XCollector\n",
    "\n",
    "x_collector = XCollector()\n",
    "\n",
    "index = -1\n",
    "# node_indices = torch.where(dataset[0].test_mask * dataset[0].y != 0)[0].tolist()\n",
    "data = dataset[0]\n",
    "\n",
    "from digg.xgraph.method.subgraphx import PlotUtils\n",
    "from digg.xgraph.method.subgraphx import find_closest_node_result\n",
    "\n",
    "# Visualization\n",
    "max_nodes = 5\n",
    "# node_idx = node_indices[20]\n",
    "node_idx = None\n",
    "# print(f'explain graph node {node_idx}')\n",
    "data.to(device)\n",
    "logits = model(data.x, data.edge_index)\n",
    "prediction = logits[node_idx].argmax(-1).item()\n",
    "\n",
    "_, explanation_results, related_preds = explainer(data.x, data.edge_index, node_idx=node_idx, max_nodes=max_nodes)\n",
    "\n",
    "explanation_results = explanation_results[prediction]\n",
    "explanation_results = explainer.read_from_MCTSInfo_list(explanation_results)\n",
    "\n",
    "plotutils = PlotUtils(dataset_name='MUTAG', is_show=True)\n",
    "explainer.visualization(explanation_results,\n",
    "                        max_nodes=max_nodes,\n",
    "                        plot_utils=plotutils,\n",
    "                        y=data.y)\n",
    "# explain graph node 515"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting captum\n",
      "  Downloading captum-0.7.0-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: matplotlib in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from captum) (3.8.4)\n",
      "Requirement already satisfied: numpy in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from captum) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.6 in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from captum) (2.1.0)\n",
      "Requirement already satisfied: tqdm in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from captum) (4.66.2)\n",
      "Requirement already satisfied: filelock in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from torch>=1.6->captum) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from torch>=1.6->captum) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from torch>=1.6->captum) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from torch>=1.6->captum) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from torch>=1.6->captum) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from torch>=1.6->captum) (2024.3.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from matplotlib->captum) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from matplotlib->captum) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from matplotlib->captum) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from matplotlib->captum) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from matplotlib->captum) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from matplotlib->captum) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from matplotlib->captum) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from matplotlib->captum) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from jinja2->torch>=1.6->captum) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/beatrixwen/miniforge3/envs/py_ten/lib/python3.10/site-packages (from sympy->torch>=1.6->captum) (1.3.0)\n",
      "Downloading captum-0.7.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: captum\n",
      "Successfully installed captum-0.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T02:09:42.324719Z",
     "iopub.status.busy": "2024-05-09T02:09:42.322626Z",
     "iopub.status.idle": "2024-05-09T02:09:42.482124Z",
     "shell.execute_reply": "2024-05-09T02:09:42.467525Z",
     "shell.execute_reply.started": "2024-05-09T02:09:42.324594Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'captum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcaptum\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'captum'"
     ]
    }
   ],
   "source": [
    "import captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T02:08:49.267630Z",
     "iopub.status.busy": "2024-05-09T02:08:49.267094Z",
     "iopub.status.idle": "2024-05-09T02:08:50.110453Z",
     "shell.execute_reply": "2024-05-09T02:08:50.109735Z",
     "shell.execute_reply.started": "2024-05-09T02:08:49.267606Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: captum 0.2.0\n",
      "Uninstalling captum-0.2.0:\n",
      "  Successfully uninstalled captum-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall captum --y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T02:09:30.111544Z",
     "iopub.status.busy": "2024-05-09T02:09:30.109643Z",
     "iopub.status.idle": "2024-05-09T02:09:34.211992Z",
     "shell.execute_reply": "2024-05-09T02:09:34.211348Z",
     "shell.execute_reply.started": "2024-05-09T02:09:30.111491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting captum\n",
      "  Downloading captum-0.7.0-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: matplotlib in /Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from captum) (3.5.0)\n",
      "Requirement already satisfied: numpy in /Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from captum) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.6 in /Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from captum) (2.3.0)\n",
      "Requirement already satisfied: tqdm in /Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from captum) (4.64.0)\n",
      "Requirement already satisfied: filelock in /Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from torch>=1.6->captum) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from torch>=1.6->captum) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from torch>=1.6->captum) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from torch>=1.6->captum) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from torch>=1.6->captum) (3.0.3)\n",
      "Requirement already satisfied: fsspec in /Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from torch>=1.6->captum) (2023.10.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from matplotlib->captum) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from matplotlib->captum) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from matplotlib->captum) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from matplotlib->captum) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from matplotlib->captum) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from matplotlib->captum) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from matplotlib->captum) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->captum) (1.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from jinja2->torch>=1.6->captum) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from sympy->torch>=1.6->captum) (1.3.0)\n",
      "Downloading captum-0.7.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: captum\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dive-into-graphs 1.1.0 requires captum==0.2.0, but you have captum 0.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed captum-0.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install captum --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.289512Z",
     "iopub.status.idle": "2024-05-08T07:19:20.289953Z",
     "shell.execute_reply": "2024-05-08T07:19:20.289675Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.289669Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Create data collector and explanation processor ---\n",
    "from digg.xgraph.evaluation import XCollector\n",
    "\n",
    "x_collector = XCollector()\n",
    "\n",
    "index = -1\n",
    "node_indices = torch.where(dataset[0].test_mask * dataset[0].y != 0)[0].tolist()\n",
    "data = dataset[0]\n",
    "\n",
    "from digg.xgraph.method.subgraphx import PlotUtils\n",
    "from digg.xgraph.method.subgraphx import find_closest_node_result\n",
    "\n",
    "# Visualization\n",
    "max_nodes = 5\n",
    "node_idx = node_indices[20]\n",
    "print(f'explain graph node {node_idx}')\n",
    "data.to(device)\n",
    "logits = model(data.x, data.edge_index)\n",
    "prediction = logits[node_idx].argmax(-1).item()\n",
    "\n",
    "_, explanation_results, related_preds =explainer(data.x, data.edge_index, node_idx=node_idx, max_nodes=max_nodes)\n",
    "\n",
    "explanation_results = explanation_results[prediction]\n",
    "explanation_results = explainer.read_from_MCTSInfo_list(explanation_results)\n",
    "\n",
    "plotutils = PlotUtils(dataset_name='ba_shapes', is_show=True)\n",
    "explainer.visualization(explanation_results,\n",
    "                        max_nodes=max_nodes,\n",
    "                        plot_utils=plotutils,\n",
    "                        y=data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.291234Z",
     "iopub.status.idle": "2024-05-08T07:19:20.291426Z",
     "shell.execute_reply": "2024-05-08T07:19:20.291319Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.291315Z"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.292880Z",
     "iopub.status.idle": "2024-05-08T07:19:20.293498Z",
     "shell.execute_reply": "2024-05-08T07:19:20.293323Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.293314Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.295497Z",
     "iopub.status.idle": "2024-05-08T07:19:20.296136Z",
     "shell.execute_reply": "2024-05-08T07:19:20.295832Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.295825Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.299744Z",
     "iopub.status.idle": "2024-05-08T07:19:20.300666Z",
     "shell.execute_reply": "2024-05-08T07:19:20.300544Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.300529Z"
    }
   },
   "outputs": [],
   "source": [
    "nx.draw(torch_geometric.utils.to_networkx(data),with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.303005Z",
     "iopub.status.idle": "2024-05-08T07:19:20.303609Z",
     "shell.execute_reply": "2024-05-08T07:19:20.303453Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.303408Z"
    }
   },
   "outputs": [],
   "source": [
    "node_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.304380Z",
     "iopub.status.idle": "2024-05-08T07:19:20.304568Z",
     "shell.execute_reply": "2024-05-08T07:19:20.304443Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.304438Z"
    }
   },
   "outputs": [],
   "source": [
    "data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.305407Z",
     "iopub.status.idle": "2024-05-08T07:19:20.305900Z",
     "shell.execute_reply": "2024-05-08T07:19:20.305592Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.305572Z"
    }
   },
   "outputs": [],
   "source": [
    "data.edge_index[1][(data.edge_index[0] == 515).nonzero(as_tuple=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.306923Z",
     "iopub.status.idle": "2024-05-08T07:19:20.308245Z",
     "shell.execute_reply": "2024-05-08T07:19:20.307653Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.307628Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_checkpoints(root='./'):\n",
    "    if osp.exists(osp.join(root, 'checkpoints')):\n",
    "        return\n",
    "    url = ('https://github.com/divelab/DIG_storage/raw/main/xgraph/checkpoints.zip')\n",
    "    path = download_url(url, root)\n",
    "    extract_zip(path, root)\n",
    "    os.unlink(path)\n",
    "\n",
    "\n",
    "model = GCN_2l(model_level='graph', dim_node=dim_node, dim_hidden=300, num_classes=num_classes)\n",
    "model.to(device)\n",
    "check_checkpoints()\n",
    "ckpt_path = osp.join('checkpoints', 'mutag', 'GCN_2l', '0', 'GCN_2l_best.ckpt')\n",
    "state_dict = compatible_state_dict(torch.load(ckpt_path, map_location='cpu')['state_dict'])\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.310621Z",
     "iopub.status.idle": "2024-05-08T07:19:20.311870Z",
     "shell.execute_reply": "2024-05-08T07:19:20.311638Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.311626Z"
    }
   },
   "outputs": [],
   "source": [
    "from digg.xgraph.method import SubgraphX\n",
    "\n",
    "explainer = SubgraphX(model, num_classes=4, device=device,\n",
    "                      explain_graph=True, reward_method='mc_l_shapley')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.312790Z",
     "iopub.status.idle": "2024-05-08T07:19:20.313063Z",
     "shell.execute_reply": "2024-05-08T07:19:20.312868Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.312863Z"
    }
   },
   "outputs": [],
   "source": [
    "node_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.313944Z",
     "iopub.status.idle": "2024-05-08T07:19:20.314804Z",
     "shell.execute_reply": "2024-05-08T07:19:20.314424Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.314417Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Create data collector and explanation processor ---\n",
    "from digg.xgraph.evaluation import XCollector\n",
    "\n",
    "x_collector = XCollector()\n",
    "\n",
    "index = -1\n",
    "node_indices = torch.where(dataset[0].test_mask * dataset[0].y != 0)[0].tolist()\n",
    "data = dataset[0]\n",
    "\n",
    "from digg.xgraph.method.subgraphx import PlotUtils\n",
    "from digg.xgraph.method.subgraphx import find_closest_node_result\n",
    "\n",
    "# Visualization\n",
    "max_nodes = 5\n",
    "# node_idx = node_indices[20]\n",
    "node_idx=None\n",
    "print(f'explain graph node {node_idx}')\n",
    "data.to(device)\n",
    "logits = model(data.x, data.edge_index)\n",
    "prediction = logits[node_idx].argmax(-1).item()\n",
    "\n",
    "_, explanation_results, related_preds =explainer(data.x, data.edge_index, node_idx=node_idx, max_nodes=max_nodes)\n",
    "\n",
    "explanation_results = explanation_results[prediction]\n",
    "explanation_results = explainer.read_from_MCTSInfo_list(explanation_results)\n",
    "\n",
    "plotutils = PlotUtils(dataset_name='ba_shapes', is_show=True)\n",
    "explainer.visualization(explanation_results,\n",
    "                        max_nodes=max_nodes,\n",
    "                        plot_utils=plotutils,\n",
    "                        y=data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### The metric result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-08T07:19:20.316435Z",
     "iopub.status.idle": "2024-05-08T07:19:20.316583Z",
     "shell.execute_reply": "2024-05-08T07:19:20.316518Z",
     "shell.execute_reply.started": "2024-05-08T07:19:20.316513Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_nodes = 5\n",
    "for node_idx in node_indices:\n",
    "    index += 1\n",
    "    print(f'explain graph node {node_idx}')\n",
    "    data.to(device)\n",
    "\n",
    "    if torch.isnan(data.y[0].squeeze()):\n",
    "        continue\n",
    "\n",
    "    logits = model(data.x, data.edge_index)\n",
    "    prediction = logits[node_idx].argmax(-1).item()\n",
    "\n",
    "    _, explanation_results, related_preds = explainer(data.x, data.edge_index, node_idx=node_idx, max_nodes=max_nodes)\n",
    "\n",
    "    explanation_results = explanation_results[prediction]\n",
    "    explanation_results = explainer.read_from_MCTSInfo_list(explanation_results)\n",
    "    result = find_closest_node_result(explanation_results, max_nodes=max_nodes)\n",
    "\n",
    "    x_collector.collect_data(result.coalition, related_preds, label=prediction)\n",
    "    if index >= 20:\n",
    "        break\n",
    "\n",
    "print(f'Fidelity: {x_collector.fidelity:.4f}\\n',\n",
    "      f'Infidelity: {x_collector.fidelity_inv:.4f}\\n'\n",
    "      f'Sparsity: {x_collector.sparsity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
