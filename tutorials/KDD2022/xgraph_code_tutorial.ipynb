{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Tutorial for GNN Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this hand-on code tutorial, we will show how to apply our DIG xgraph APIs to explain a well-trained model. Specifically, we will demonstrate two methods **GNNExplainer** and **SubgraphX** on the node classification dataset BA-shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## GNN explainability\n",
    "Graph Neural Networks are usually treated as black-boxes and lacking explainability. Without reasoning the prediction procedures of GNNs, we do not understand GNN models and do not know whether the models work in our expected way, thus preventing their use in critical applications pertaining to fairness, privacy, and safety."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load the dataset BA-shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:19:42.704640Z",
     "iopub.status.busy": "2024-04-16T20:19:42.703066Z",
     "iopub.status.idle": "2024-04-16T20:19:44.592054Z",
     "shell.execute_reply": "2024-04-16T20:19:44.591330Z",
     "shell.execute_reply.started": "2024-04-16T20:19:42.704563Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# import torchvision\n",
    "# from torchvision.datasets import CIFAR10\n",
    "# from torchvision import transforms\n",
    "# PyTorch Lightning\n",
    "# Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "# !pip install --quiet pytorch-lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:20:11.003530Z",
     "iopub.status.busy": "2024-04-16T20:20:10.998837Z",
     "iopub.status.idle": "2024-04-16T20:20:11.031904Z",
     "shell.execute_reply": "2024-04-16T20:20:11.031495Z",
     "shell.execute_reply.started": "2024-04-16T20:20:11.003404Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y9/hy0mnzl536ng5c4qz99ppmf00000gn/T/ipykernel_91692/3751370899.py:12: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np \n",
    "import time\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "sns.set()\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "# Torchvision\n",
    "# import torchvision\n",
    "# from torchvision.datasets import CIFAR10\n",
    "# from torchvision import transforms\n",
    "# PyTorch Lightning\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "    !pip install --quiet pytorch-lightning>=1.4\n",
    "    import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = \"../data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"../saved_models/tutorial7\"\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"mps\")\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:14:28.112750Z",
     "iopub.status.busy": "2024-04-16T20:14:28.102012Z",
     "iopub.status.idle": "2024-04-16T20:14:28.156569Z",
     "shell.execute_reply": "2024-04-16T20:14:28.154279Z",
     "shell.execute_reply.started": "2024-04-16T20:14:28.112426Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import os.path as osp\n",
    "sys.path.insert(0, os.sep.join(os.path.abspath('').split(os.sep)[:-2]))\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "\n",
    "from dig.xgraph.dataset import SynGraphDataset\n",
    "# from dig.xgraph.models import *\n",
    "from dig.xgraph.utils.compatibility import compatible_state_dict\n",
    "from dig.xgraph.utils.init import fix_random_seed\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "fix_random_seed(123)\n",
    "# dataset = SynGraphDataset('./datasets', 'BA_shapes')\n",
    "DATASET_PATH='../data'\n",
    "dataset = torch_geometric.datasets.TUDataset(root=DATASET_PATH, name=\"MUTAG\")\n",
    "dataset.data.x = dataset.data.x.to(torch.float32)\n",
    "dataset.data.x = dataset.data.x[:, :1]\n",
    "dim_node = dataset.num_node_features\n",
    "num_classes = dataset.num_classes\n",
    "\n",
    "data = dataset[0]\n",
    "# target_node_indices = torch.where(dataset[0].test_mask * dataset[0].y != 0)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:14:09.368065Z",
     "iopub.status.busy": "2024-04-16T20:14:09.363216Z",
     "iopub.status.idle": "2024-04-16T20:14:09.381405Z",
     "shell.execute_reply": "2024-04-16T20:14:09.380879Z",
     "shell.execute_reply.started": "2024-04-16T20:14:09.367660Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:25:18.664855Z",
     "iopub.status.busy": "2024-04-16T20:25:18.657160Z",
     "iopub.status.idle": "2024-04-16T20:25:18.698240Z",
     "shell.execute_reply": "2024-04-16T20:25:18.697585Z",
     "shell.execute_reply.started": "2024-04-16T20:25:18.664392Z"
    }
   },
   "outputs": [],
   "source": [
    "class GNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in, c_hidden, c_out, num_layers=2, layer_name=\"GraphConv\", dp_rate=0.1, **kwargs):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Dimension of input features\n",
    "            c_hidden - Dimension of hidden features\n",
    "            c_out - Dimension of the output features. Usually number of classes in classification\n",
    "            num_layers - Number of \"hidden\" graph layers\n",
    "            layer_name - String of the graph layer to use\n",
    "            dp_rate - Dropout rate to apply throughout the network\n",
    "            kwargs - Additional arguments for the graph layer (e.g. number of heads for GAT)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        gnn_layer = gnn_layer_by_name[layer_name]\n",
    "        \n",
    "        layers = []\n",
    "        in_channels, out_channels = c_in, c_hidden\n",
    "        for l_idx in range(num_layers-1):\n",
    "            layers += [\n",
    "                gnn_layer(in_channels=in_channels, \n",
    "                          out_channels=out_channels,\n",
    "                          **kwargs),\n",
    "                nn.ReLU(inplace=True)\n",
    "                # ,nn.Dropout(dp_rate)\n",
    "            ]\n",
    "            in_channels = c_hidden\n",
    "        layers += [gnn_layer(in_channels=in_channels, \n",
    "                             out_channels=c_out,\n",
    "                             **kwargs)]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            x - Input features per node\n",
    "            edge_index - List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "        \"\"\"\n",
    "        for l in self.layers:\n",
    "            # For graph layers, we need to add the \"edge_index\" tensor as additional input\n",
    "            # All PyTorch Geometric graph layer inherit the class \"MessagePassing\", hence\n",
    "            # we can simply check the class type.\n",
    "            if isinstance(l, geom_nn.MessagePassing):\n",
    "                x = l(x, edge_index)\n",
    "            else:\n",
    "                x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:20:18.632462Z",
     "iopub.status.busy": "2024-04-16T20:20:18.631852Z",
     "iopub.status.idle": "2024-04-16T20:20:18.648824Z",
     "shell.execute_reply": "2024-04-16T20:20:18.645637Z",
     "shell.execute_reply.started": "2024-04-16T20:20:18.632382Z"
    }
   },
   "outputs": [],
   "source": [
    "class GraphGNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in, c_hidden, c_out, dp_rate_linear=0.5, **kwargs):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Dimension of input features\n",
    "            c_hidden - Dimension of hidden features\n",
    "            c_out - Dimension of output features (usually number of classes)\n",
    "            dp_rate_linear - Dropout rate before the linear layer (usually much higher than inside the GNN)\n",
    "            kwargs - Additional arguments for the GNNModel object\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.GNN = GNNModel(c_in=c_in, \n",
    "                            c_hidden=c_hidden, \n",
    "                            c_out=c_hidden, # Not our prediction output yet!\n",
    "                            **kwargs)\n",
    "        self.head = nn.Sequential(\n",
    "            # nn.Dropout(dp_rate_linear),\n",
    "            nn.Linear(c_hidden, c_out)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, batch_idx):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            x - Input features per node\n",
    "            edge_index - List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "            batch_idx - Index of batch element for each node\n",
    "        \"\"\"\n",
    "        x = self.GNN(x, edge_index)\n",
    "        # x = geom_nn.global_mean_pool(x, batch_idx) # Average pooling\n",
    "        x = geom_nn.global_max_pool(x, batch_idx) # Average pooling\n",
    "        # x = geom_nn.global_add_pool(x, batch_idx) # sum pooling\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:20:19.665870Z",
     "iopub.status.busy": "2024-04-16T20:20:19.664828Z",
     "iopub.status.idle": "2024-04-16T20:20:19.690556Z",
     "shell.execute_reply": "2024-04-16T20:20:19.689829Z",
     "shell.execute_reply.started": "2024-04-16T20:20:19.665830Z"
    }
   },
   "outputs": [],
   "source": [
    "class GraphLevelGNN(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, **model_kwargs):\n",
    "        super().__init__()\n",
    "        # Saving hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.model = GraphGNNModel(**model_kwargs)\n",
    "        self.loss_module = nn.BCEWithLogitsLoss() if self.hparams.c_out == 1 else nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, data, mode=\"train\"):\n",
    "        x, edge_index, batch_idx = data.x, data.edge_index, data.batch\n",
    "        x = self.model(x, edge_index, batch_idx)\n",
    "        x = x.squeeze(dim=-1)\n",
    "        \n",
    "        if self.hparams.c_out == 1:\n",
    "            preds = (x > 0).float()\n",
    "            try: \n",
    "                data.y = data.y.float()\n",
    "            except: pass\n",
    "        else:\n",
    "            preds = x.argmax(dim=-1)\n",
    "        try: \n",
    "            loss = self.loss_module(x, data.y)\n",
    "            acc = (preds == data.y).sum().float() / preds.shape[0]\n",
    "        except:\n",
    "            loss = 0\n",
    "            acc = 0\n",
    "\n",
    "        return loss,acc,preds\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=1e-2, weight_decay=0.0) # High lr because of small dataset and small model\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc,_ = self.forward(batch, mode=\"train\")\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', acc)\n",
    "        return loss\n",
    "\n",
    "    # def validation_step(self, batch, batch_idx):\n",
    "    #     _, acc,preds = self.forward(batch, mode=\"val\")\n",
    "    #     self.log('val_acc', acc)\n",
    "    #     # self.log('val_pred', preds)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        _, acc,_ = self.forward(batch, mode=\"test\")\n",
    "        self.log('test_acc', acc)\n",
    "        # self.log('test_pred', pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:22:45.966266Z",
     "iopub.status.busy": "2024-04-16T20:22:45.963296Z",
     "iopub.status.idle": "2024-04-16T20:22:47.858677Z",
     "shell.execute_reply": "2024-04-16T20:22:47.858126Z",
     "shell.execute_reply.started": "2024-04-16T20:22:45.966165Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/ENZYMES.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "tu_dataset = torch_geometric.datasets.TUDataset(root=DATASET_PATH, name=\"ENZYMES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:22:47.860662Z",
     "iopub.status.busy": "2024-04-16T20:22:47.860376Z",
     "iopub.status.idle": "2024-04-16T20:22:47.922282Z",
     "shell.execute_reply": "2024-04-16T20:22:47.920540Z",
     "shell.execute_reply.started": "2024-04-16T20:22:47.860643Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch_geometric.data.data.Data"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tu2=tu_dataset.copy()\n",
    "type(tu2.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:23:02.515753Z",
     "iopub.status.busy": "2024-04-16T20:23:02.513810Z",
     "iopub.status.idle": "2024-04-16T20:23:02.957745Z",
     "shell.execute_reply": "2024-04-16T20:23:02.957119Z",
     "shell.execute_reply.started": "2024-04-16T20:23:02.515664Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(tu2.y)): \n",
    "    tu2.y[i]=max(torch.bincount(tu2[i].edge_index[0,:]))\n",
    "    # tu2.y[i]=sum(torch.bincount(tu2[i].edge_index[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:23:09.535493Z",
     "iopub.status.busy": "2024-04-16T20:23:09.520657Z",
     "iopub.status.idle": "2024-04-16T20:23:09.550973Z",
     "shell.execute_reply": "2024-04-16T20:23:09.550335Z",
     "shell.execute_reply.started": "2024-04-16T20:23:09.535148Z"
    }
   },
   "outputs": [],
   "source": [
    "thres=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:23:11.274856Z",
     "iopub.status.busy": "2024-04-16T20:23:11.274061Z",
     "iopub.status.idle": "2024-04-16T20:23:11.292207Z",
     "shell.execute_reply": "2024-04-16T20:23:11.289057Z",
     "shell.execute_reply.started": "2024-04-16T20:23:11.274819Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "tu2.data.y=(tu2.y>thres).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:23:13.269063Z",
     "iopub.status.busy": "2024-04-16T20:23:13.268658Z",
     "iopub.status.idle": "2024-04-16T20:23:13.287552Z",
     "shell.execute_reply": "2024-04-16T20:23:13.284265Z",
     "shell.execute_reply.started": "2024-04-16T20:23:13.269033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "        1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "        0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "        0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "        1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tu2.data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:23:15.628172Z",
     "iopub.status.busy": "2024-04-16T20:23:15.627944Z",
     "iopub.status.idle": "2024-04-16T20:23:15.633134Z",
     "shell.execute_reply": "2024-04-16T20:23:15.632665Z",
     "shell.execute_reply.started": "2024-04-16T20:23:15.628150Z"
    }
   },
   "outputs": [],
   "source": [
    "tu2.data.x=tu2.x[:,:1]\n",
    "# tu2.data.x=torch.ones(tu2.x.shape)\n",
    "tu2.data.x=torch.randn(tu2.x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:23:16.916032Z",
     "iopub.status.busy": "2024-04-16T20:23:16.915431Z",
     "iopub.status.idle": "2024-04-16T20:23:16.936045Z",
     "shell.execute_reply": "2024-04-16T20:23:16.935313Z",
     "shell.execute_reply.started": "2024-04-16T20:23:16.915995Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.manual_seed(42)\n",
    "# tu_dataset.shuffle()\n",
    "# train_dataset = tu_dataset[:500]\n",
    "# test_dataset = tu_dataset[500:]\n",
    "torch.manual_seed(42)\n",
    "tu2_shuffle=tu2.shuffle()\n",
    "train_dataset = tu2_shuffle[:500]\n",
    "test_dataset = tu2_shuffle[500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using a data loader, we encounter a problem with batching $N$ graphs. Each graph in the batch can have a different number of nodes and edges, and hence we would require a lot of padding to obtain a single tensor. Torch geometric uses a different, more efficient approach: we can view the $N$ graphs in a batch as a single large graph with concatenated node and edge list. As there is no edge between the $N$ graphs, running GNN layers on the large graph gives us the same output as running the GNN on each graph separately. Visually, this batching strategy is visualized below (figure credit - PyTorch Geometric team, [tutorial here](https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing#scrollTo=2owRWKcuoALo)).\n",
    "\n",
    "<center width=\"100%\"><img src=\"torch_geometric_stacking_graphs.png\" width=\"600px\"></center>\n",
    "\n",
    "The adjacency matrix is zero for any nodes that come from two different graphs, and otherwise according to the adjacency matrix of the individual graph. Luckily, this strategy is already implemented in torch geometric, and hence we can use the corresponding data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:23:43.226270Z",
     "iopub.status.busy": "2024-04-16T20:23:43.224460Z",
     "iopub.status.idle": "2024-04-16T20:23:43.237238Z",
     "shell.execute_reply": "2024-04-16T20:23:43.236528Z",
     "shell.execute_reply.started": "2024-04-16T20:23:43.226183Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch_geometric.nn as geom_nn\n",
    "import torch_geometric.data as geom_data\n",
    "gnn_layer_by_name = {\n",
    "    \"GCN\": geom_nn.GCNConv,\n",
    "    \"GAT\": geom_nn.GATConv,\n",
    "    \"GIN\": geom_nn.GINConv,\n",
    "    \"GraphConv\": geom_nn.GraphConv\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:23:44.226546Z",
     "iopub.status.busy": "2024-04-16T20:23:44.226089Z",
     "iopub.status.idle": "2024-04-16T20:23:44.241595Z",
     "shell.execute_reply": "2024-04-16T20:23:44.240316Z",
     "shell.execute_reply.started": "2024-04-16T20:23:44.226514Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beatrixwen/miniforge3/envs/tensorflow/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "graph_train_loader = geom_data.DataLoader(train_dataset, batch_size=15, shuffle=True)\n",
    "graph_val_loader = geom_data.DataLoader(test_dataset, batch_size=15) # Additional loader if you want to change to a larger dataset\n",
    "graph_test_loader = geom_data.DataLoader(test_dataset, batch_size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load a batch below to see the batching in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:23:46.853255Z",
     "iopub.status.busy": "2024-04-16T20:23:46.852782Z",
     "iopub.status.idle": "2024-04-16T20:23:46.900667Z",
     "shell.execute_reply": "2024-04-16T20:23:46.900232Z",
     "shell.execute_reply.started": "2024-04-16T20:23:46.853220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: DataBatch(edge_index=[2, 2192], x=[569, 1], y=[15], batch=[569], ptr=[16])\n",
      "Labels: tensor([0, 0, 1, 1, 1, 1, 0, 0, 0, 0])\n",
      "Batch indices: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(graph_test_loader))\n",
    "print(\"Batch:\", batch)\n",
    "print(\"Labels:\", batch.y[:10])\n",
    "print(\"Batch indices:\", batch.batch[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:23:48.649712Z",
     "iopub.status.busy": "2024-04-16T20:23:48.646829Z",
     "iopub.status.idle": "2024-04-16T20:23:48.672392Z",
     "shell.execute_reply": "2024-04-16T20:23:48.671711Z",
     "shell.execute_reply.started": "2024-04-16T20:23:48.649618Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_graph_classifier(model_name,train_loader=graph_train_loader,test_loader=graph_test_loader, **model_kwargs):\n",
    "    pl.seed_everything(42)\n",
    "    \n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "    root_dir = os.path.join(CHECKPOINT_PATH, \"GraphLevel\" + model_name)\n",
    "    os.makedirs(root_dir, exist_ok=True)\n",
    "    trainer = pl.Trainer(default_root_dir=root_dir,\n",
    "                         # callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n",
    "                         accelerator=\"cpu\",# if str(device).startswith(\"cuda\") else \"cpu\",\n",
    "                         devices=1,\n",
    "                         max_epochs=500,\n",
    "                         enable_progress_bar=False)\n",
    "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"GraphLevel{model_name}.ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        # print(\"Found pretrained model, loading...\")\n",
    "        # model = GraphLevelGNN.load_from_checkpoint(pretrained_filename)\n",
    "        pl.seed_everything(42)\n",
    "        model = GraphLevelGNN(c_in=tu2.num_node_features, \n",
    "                              c_out=1 if tu2.num_classes==2 else tu2.num_classes, \n",
    "                              **model_kwargs)\n",
    "        trainer.fit(model, graph_train_loader, graph_val_loader)\n",
    "        # model = GraphLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "    else:\n",
    "        pl.seed_everything(42)\n",
    "        model = GraphLevelGNN(c_in=tu2.num_node_features, \n",
    "                              c_out=1 if tu2.num_classes==2 else tu2.num_classes, \n",
    "                              **model_kwargs)\n",
    "        trainer.fit(model, graph_train_loader, graph_val_loader)\n",
    "        # model = GraphLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "    # Test best model on validation and test set\n",
    "    train_result = trainer.test(model, train_loader, verbose=False)\n",
    "    test_result = trainer.test(model, test_loader, verbose=False)\n",
    "    # test_pred = trainer.predict(model, graph_test_loader, return_predictions=True)\n",
    "    result = {\"test\": test_result[0]['test_acc'], \"train\": train_result[0]['test_acc']\n",
    "              # ,\"pred_y\": test_pred\n",
    "            } \n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the well-trained GCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:25:48.223550Z",
     "iopub.status.busy": "2024-04-16T20:25:48.221661Z",
     "iopub.status.idle": "2024-04-16T20:25:48.391692Z",
     "shell.execute_reply": "2024-04-16T20:25:48.386377Z",
     "shell.execute_reply.started": "2024-04-16T20:25:48.223483Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GraphLevelGNN:\n\tUnexpected key(s) in state_dict: \"model.GNN.layers.4.lin_rel.weight\", \"model.GNN.layers.4.lin_rel.bias\", \"model.GNN.layers.4.lin_root.weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m ckpt_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/beatrixwen/Downloads/checkpoint.ckpt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     19\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m compatible_state_dict(torch\u001b[38;5;241m.\u001b[39mload(ckpt_path, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 20\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GraphLevelGNN:\n\tUnexpected key(s) in state_dict: \"model.GNN.layers.4.lin_rel.weight\", \"model.GNN.layers.4.lin_rel.bias\", \"model.GNN.layers.4.lin_root.weight\". "
     ]
    }
   ],
   "source": [
    "def check_checkpoints(root='./'):\n",
    "    if osp.exists(osp.join(root, 'checkpoints')):\n",
    "        return\n",
    "    url = ('https://github.com/divelab/DIG_storage/raw/main/xgraph/checkpoints.zip')\n",
    "    path = download_url(url, root)\n",
    "    extract_zip(path, root)\n",
    "    os.unlink(path)\n",
    "\n",
    "\n",
    "# model = GCN_2l(model_level='node', dim_node=dim_node, dim_hidden=300, num_classes=num_classes)\n",
    "# model.to(device)\n",
    "# check_checkpoints()\n",
    "# ckpt_path = osp.join('checkpoints', 'ba_shapes', 'GCN_2l', '0', 'GCN_2l_best.ckpt')\n",
    "model = GraphLevelGNN(c_in=tu2.num_node_features, \n",
    "                              c_out=1 if tu2.num_classes==2 else tu2.num_classes,\n",
    "                      c_hidden=16)\n",
    "                              # **model_kwargs)\n",
    "ckpt_path='/Users/beatrixwen/Downloads/checkpoint.ckpt'\n",
    "state_dict = compatible_state_dict(torch.load(ckpt_path, map_location='cpu')['model_state_dict'])\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-16T20:23:03.042003Z",
     "iopub.status.idle": "2024-04-16T20:23:03.044568Z",
     "shell.execute_reply": "2024-04-16T20:23:03.044089Z",
     "shell.execute_reply.started": "2024-04-16T20:23:03.044072Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### GNNExplainer\n",
    "\n",
    "GNNExplainer learns soft masks for edges and node features to identify important input information. The masks are randomly initialized and updated to maximize the mutual information between original predictions and perturbed graphs.\n",
    "Here we setup **GNNExplainer** and take it to explain the predictions for 20 target nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-16T20:23:03.045523Z",
     "iopub.status.idle": "2024-04-16T20:23:03.046765Z",
     "shell.execute_reply": "2024-04-16T20:23:03.046049Z",
     "shell.execute_reply.started": "2024-04-16T20:23:03.045983Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dig.xgraph.method import GNNExplainer\n",
    "from dig.xgraph.evaluation import XCollector\n",
    "\n",
    "gnnexplainer = GNNExplainer(model, epochs=100, lr=0.01, explain_graph=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### SubgraphX\n",
    "SubgraphX explores subgraph-level explanations for graph neural networks. It employs the Monte Carlo Tree Search algorithm to efficiently explore different subgraphs via node pruning and select the most important subgraph as the explanation. The importance of subgraphs is measured by Shapley values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-16T20:23:03.048605Z",
     "iopub.status.idle": "2024-04-16T20:23:03.049295Z",
     "shell.execute_reply": "2024-04-16T20:23:03.048941Z",
     "shell.execute_reply.started": "2024-04-16T20:23:03.048911Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dig.xgraph.method import SubgraphX\n",
    "\n",
    "subgraphx_explainer = SubgraphX(model,\n",
    "                                num_classes=num_classes,\n",
    "                                device=device,\n",
    "                                explain_graph=False,\n",
    "                                reward_method='nc_mc_l_shapley')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "We provide the visualization APIs for Synthetic, Text2Graph and Molecules datasets to provide human-intelligible explanation visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-16T20:23:03.051100Z",
     "iopub.status.idle": "2024-04-16T20:23:03.052147Z",
     "shell.execute_reply": "2024-04-16T20:23:03.051869Z",
     "shell.execute_reply.started": "2024-04-16T20:23:03.051836Z"
    }
   },
   "outputs": [],
   "source": [
    "from dig.xgraph.method.subgraphx import PlotUtils\n",
    "from dig.xgraph.method.subgraphx import MCTS\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "data = dataset[0].to(device)\n",
    "node_indices = torch.where(dataset[0].test_mask * dataset[0].y != 0)[0].tolist()\n",
    "node_idx = node_indices[20]\n",
    "\n",
    "subgraph_x, subgraph_edge_index, subset, edge_mask, kwargs = \\\n",
    "    MCTS.__subgraph__(node_idx, data.x, data.edge_index, num_hops=2)\n",
    "new_node_idx = torch.argwhere(subset == node_idx)[0]\n",
    "\n",
    "subgraph_y = data.y[subset].to('cpu')\n",
    "vis_graph = to_networkx(Data(x=subgraph_x, edge_index=subgraph_edge_index))\n",
    "plotutils = PlotUtils(dataset_name='ba_shapes')\n",
    "plotutils.plot(vis_graph, nodelist=[], figname=None, y=subgraph_y, node_idx=new_node_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization results for the GNNExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-16T20:23:03.053589Z",
     "iopub.status.idle": "2024-04-16T20:23:03.054126Z",
     "shell.execute_reply": "2024-04-16T20:23:03.053940Z",
     "shell.execute_reply.started": "2024-04-16T20:23:03.053927Z"
    }
   },
   "outputs": [],
   "source": [
    "sparsity = 0.7\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualization\n",
    "gnnexplainer_related_preds = \\\n",
    "    gnnexplainer(data.x, data.edge_index, sparsity=sparsity, num_classes=num_classes, node_idx=node_idx)\n",
    "ax, G = gnnexplainer.visualize_graph(node_idx=node_idx, \n",
    "                                     edge_index=data.edge_index, \n",
    "                                     edge_mask=gnnexplainer_related_preds[1][prediction], \n",
    "                                     y=data.y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization results for the SubgraphX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-16T20:23:03.057126Z",
     "iopub.status.idle": "2024-04-16T20:23:03.058156Z",
     "shell.execute_reply": "2024-04-16T20:23:03.057802Z",
     "shell.execute_reply.started": "2024-04-16T20:23:03.057788Z"
    }
   },
   "outputs": [],
   "source": [
    "from dig.xgraph.method.subgraphx import PlotUtils\n",
    "from dig.xgraph.method.subgraphx import find_closest_node_result\n",
    "\n",
    "# Visualization\n",
    "max_nodes = 5\n",
    "node_idx = node_indices[20]\n",
    "print(f'explain graph node {node_idx}')\n",
    "data.to(device)\n",
    "logits = model(data.x, data.edge_index)\n",
    "prediction = logits[node_idx].argmax(-1).item()\n",
    "\n",
    "_, explanation_results, related_preds = \\\n",
    "    subgraphx_explainer(data.x, data.edge_index, node_idx=node_idx, max_nodes=max_nodes)\n",
    "\n",
    "explanation_results = explanation_results[prediction]\n",
    "explanation_results = subgraphx_explainer.read_from_MCTSInfo_list(explanation_results)\n",
    "\n",
    "plotutils = PlotUtils(dataset_name='ba_shapes', is_show=True)\n",
    "subgraphx_explainer.visualization(explanation_results,\n",
    "                        max_nodes=max_nodes,\n",
    "                        plot_utils=plotutils,\n",
    "                        y=data.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Metric\n",
    "Here we apply two metric Fidelity and Sparsity to compare these two explainability methods.\n",
    "Fidelity is the probability difference between the original prediction and new prediction when masking the important explanation results. In addition, Sparsity is the ratio of the number of edges not in the final explanation of edges.\n",
    "\n",
    " Next, we take GNNExplainer and SubgraphX to explain the same model predictions. Here we control similar sparsity scores and compare the fidelity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-16T20:23:03.064961Z",
     "iopub.status.idle": "2024-04-16T20:23:03.065883Z",
     "shell.execute_reply": "2024-04-16T20:23:03.065760Z",
     "shell.execute_reply.started": "2024-04-16T20:23:03.065746Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sparsity = 0.15\n",
    "gnnexplainer_collector = XCollector()\n",
    "\n",
    "max_nodes = 5\n",
    "subgraphx_collector = XCollector()\n",
    "\n",
    "for data_idx, node_idx in enumerate(target_node_indices[:20]):\n",
    "    data.to(device)\n",
    "\n",
    "    logits = model(data.x, data.edge_index)\n",
    "    prediction = logits[node_idx].argmax(-1).item()\n",
    "\n",
    "    gnnexplainer_edge_masks, \\\n",
    "    gnnexplainer_hard_edge_masks, \\\n",
    "    gnnexplainer_related_preds = \\\n",
    "        gnnexplainer(data.x, data.edge_index,\n",
    "                     sparsity=sparsity,\n",
    "                     num_classes=num_classes,\n",
    "                     node_idx=node_idx)\n",
    "\n",
    "    _, subgraphx_explanation_results, subgraphx_related_preds = \\\n",
    "        subgraphx_explainer(data.x, data.edge_index, node_idx=node_idx, max_nodes=max_nodes)\n",
    "    subgraphx_explanation_results = subgraphx_explanation_results[prediction]\n",
    "\n",
    "    gnnexplainer_collector.collect_data(\n",
    "        gnnexplainer_hard_edge_masks, gnnexplainer_related_preds, prediction)\n",
    "    subgraphx_collector.collect_data(\n",
    "        subgraphx_explanation_results[0]['coalition'], subgraphx_related_preds, label=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-16T20:23:03.070877Z",
     "iopub.status.idle": "2024-04-16T20:23:03.073116Z",
     "shell.execute_reply": "2024-04-16T20:23:03.072407Z",
     "shell.execute_reply.started": "2024-04-16T20:23:03.072259Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'GNNExplainer Fidelity: {gnnexplainer_collector.fidelity:.4f}\\n',\n",
    "      f'GNNExplainer Sparsity: {gnnexplainer_collector.sparsity:.4f}')\n",
    "print(f'SubgraphX Fidelity: {subgraphx_collector.fidelity:.4f}\\n',\n",
    "      f'SubgraphX Sparsity: {subgraphx_collector.sparsity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
